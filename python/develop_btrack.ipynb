{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example usage of segmentation to btrack to napari visualization\n",
    "\n",
    "This example uses TIF files saved out from segmentation using *stardist3D*, although will work for other segmentation pipelines too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "import btrack\n",
    "import napari\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from skimage.io import imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/Users/dane/Documents/CellTrackingProjects/AU565/images/AU02001/Analysis/PC/intermediate_files/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(os.path.join(PATH, 'tracking', 'A1','field_1', 'masks','mask*.tif'))\n",
    "\n",
    "# sort the files numerically\n",
    "#files = sorted(files, key=lambda f: int(f[len(os.path.join(PATH, 'labels_')):-4]))\n",
    "files = sorted(files)\n",
    "phase_stack_filename = glob.glob(os.path.join(PATH, \"AU02001_P_A1_1_reg_stack.tif\"))[0]\n",
    "phase_stack = imread(phase_stack_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files\n",
    "#phase_stack_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### method 1 - using a numpy array\n",
    "\n",
    "In this example, each image from the timelapse is a 3D volume (32 x 1200 x 1200) and there are 10 timepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation_arr(files):\n",
    "    \"\"\"Segmentation as numpy array.\"\"\"\n",
    "    \n",
    "    stack = []\n",
    "    for filename in files:\n",
    "        img = imread(filename)\n",
    "        stack.append(img)\n",
    "    return np.stack(stack, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = segmentation_arr(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we print out the shape of the stack (T, Z, Y, X):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### method 2 - using a generator\n",
    "\n",
    "This is useful if you're resource constrained and don't want to load all of the image data, or they are stored in an unusual format. Note that the generator produces a numpy array for each image..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation_generator(files):\n",
    "    \"\"\"Segmentation generator\"\"\"\n",
    "    \n",
    "    for filename in files:\n",
    "        img = imread(filename)\n",
    "        yield img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = segmentation_generator(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## localizing the objects\n",
    "\n",
    "Now we use a utility function to localise the objects in the segmentation, and also apply anisotropic scaling (using the `scale` option, here the z-values are scaled by 2x). Note that we can also use scikit-image `regionprops` to calculate properties for each object, using the `properties` keyword:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "obj_from_arr = btrack.utils.segmentation_to_objects(stack, properties=('area', ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inspect the first object\n",
    "obj_from_arr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_from_generator = btrack.utils.segmentation_to_objects(\n",
    "    generator, \n",
    "    properties = ('area', 'major_axis_length')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the first object\n",
    "obj_from_generator[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run btrack with the objects\n",
    "\n",
    "We will use the objects from the generator here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise a tracker session using a context manager\n",
    "with btrack.BayesianTracker() as tracker:\n",
    "\n",
    "    # configure the tracker using a config file\n",
    "    tracker.configure_from_file('../models/cell_config_AU565.json')\n",
    "    tracker.max_search_radius = 100\n",
    "\n",
    "    # append the objects to be tracked\n",
    "    tracker.append(obj_from_generator)\n",
    "\n",
    "    # set the volume\n",
    "    tracker.volume=((0, 1408), (0, 1040), (-1e5, 1e5))\n",
    "\n",
    "    # track them (in interactive mode)\n",
    "    tracker.track_interactive(step_size=200)\n",
    "\n",
    "    # generate hypotheses and run the global optimizer\n",
    "    tracker.optimize()\n",
    "\n",
    "    tracker.export(os.path.join(PATH, 'tracking.h5'), obj_type='obj_type_1')\n",
    "\n",
    "    # get the tracks in a format for napari visualization\n",
    "    data, properties, graph = tracker.to_napari(ndim=2)\n",
    "    \n",
    "    #tracks = tracker.tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualize with napari\n",
    "\n",
    "Note that we also set the scale of the images here to account for the anisotropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#viewer = napari.Viewer()\n",
    "#viewer = napari.view_image(img_p_stack, name = \"phase image\")\n",
    "\n",
    "viewer = napari.view_image(phase_stack, name = \"phase image\")\n",
    "viewer.add_labels(stack,  name='Segmentation')\n",
    "viewer.add_tracks(data, properties=properties, graph=graph, name='Tracks')\n",
    "\n",
    "napari.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
