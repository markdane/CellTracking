{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example usage of segmentation to btrack to napari visualization\n",
    "\n",
    "This example uses TIF files saved out from segmentation using *stardist3D*, although will work for other segmentation pipelines too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'napari'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_21395/1110212083.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbtrack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnapari\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'napari'"
     ]
    }
   ],
   "source": [
    "import os, re, glob\n",
    "import h5py\n",
    "import btrack\n",
    "import napari\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io, filters, util, segmentation, morphology, measure, restoration, exposure\n",
    "from scipy import stats, spatial, ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_name = \"CBn\"\n",
    "plateID = \"AU03501\"\n",
    "well = \"A1\"\n",
    "field = \"field_1\"\n",
    "field_num = field.replace(\"field_\",\"\")\n",
    "ch1_name = 'NR'\n",
    "ch2_name = 'CC'\n",
    "data_path = '/home/exacloud/gscratch/HeiserLab/images/'\n",
    "#data_path = '/Users/dane/Documents/CellTrackingProjects/AU565/images/'\n",
    "int_path = os.path.join(data_path+plateID,\"Analysis\",pipeline_name,\"intermediate_files/\")\n",
    "\n",
    "reg_filename = os.path.join(int_path,plateID+\"_R_\"+well+\"_\"+field_num+\"_reg_stack.tif\")\n",
    "mask_filename = reg_filename.replace(\"_reg_stack.tif\", \"_nuc_masks_stack.png\")\n",
    "tracking_path = os.path.join(int_path,'tracking/')\n",
    "if not os.path.exists(tracking_path+well+\"/\"+field+\"/nuc_masks/\"):\n",
    "        os.makedirs(tracking_path+well+\"/\"+field+\"/nuc_masks/\")\n",
    "if not os.path.exists(tracking_path+well+\"/\"+field+\"/reg\"):\n",
    "        os.makedirs(tracking_path+well+\"/\"+field+\"/reg\")\n",
    "if not os.path.exists(tracking_path+well+\"/\"+field+\"/results\"):\n",
    "        os.makedirs(tracking_path+well+\"/\"+field+\"/results\")\n",
    "if not os.path.exists(tracking_path+well+\"/\"+field+\"/filtered_masks\"):\n",
    "        os.makedirs(tracking_path+well+\"/\"+field+\"/filtered_masks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_21395/598186151.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mnuc_reporter_file_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnuc_reporter_file_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mnuc_reporter_stack_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplateID\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_R_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mwell\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfield_num\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_reg_stack.tif\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mnuc_reporter_stack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnuc_reporter_stack_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfirst_frame\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlast_frame\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "first_frame = 8\n",
    "last_frame = 18\n",
    "nuc_mask_file_names = glob.glob(os.path.join(int_path, 'tracking', well,field, 'nuc_masks','mask*.tif'))[first_frame:last_frame]\n",
    "nuc_reporter_file_names = glob.glob(os.path.join(int_path, 'tracking', well, field, 'reg','t*.tif'))[first_frame:last_frame]\n",
    "\n",
    "# sort the files numerically\n",
    "#files = sorted(files, key=lambda f: int(f[len(os.path.join(int_path, 'labels_')):-4]))\n",
    "nuc_mask_file_names = sorted(nuc_mask_file_names)\n",
    "nuc_reporter_file_names = sorted(nuc_reporter_file_names)\n",
    "\n",
    "nuc_reporter_stack_filename = glob.glob(os.path.join(int_path, plateID+\"_R_\"+well+\"_\"+field_num+\"_reg_stack.tif\"))[0]\n",
    "nuc_reporter_stack = io.imread(nuc_reporter_stack_filename)[first_frame:last_frame,:,:]\n",
    "\n",
    "phase_stack_filename = glob.glob(os.path.join(int_path, plateID+\"_P_\"+well+\"_\"+field_num+\"_reg_stack.tif\"))[0]\n",
    "phase_stack = io.imread(phase_stack_filename)[first_frame:last_frame,:,:]\n",
    "\n",
    "nuc_reporter_stack_filename\n",
    "#nuc_reporter_stack.shape\n",
    "#len(nuc_reporter_file_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### method 1 - using a numpy array\n",
    "\n",
    "In this example, each image from the timelapse is a 3D volume (32 x 1200 x 1200) and there are 10 timepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation_arr(files):\n",
    "    \"\"\"Segmentation as numpy array.\"\"\"\n",
    "    \n",
    "    stack = []\n",
    "    for filename in files:\n",
    "        img = io.imread(filename)\n",
    "        stack.append(img)\n",
    "    return np.stack(stack, axis=0)\n",
    "\n",
    "nuc_mask_stack = segmentation_arr(nuc_mask_file_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = segmentation_arr(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we print out the shape of the stack (T, Z, Y, X):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### method 2 - using a generator\n",
    "\n",
    "This is useful if you're resource constrained and don't want to load all of the image data, or they are stored in an unusual format. Note that the generator produces a numpy array for each image..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation_generator(files):\n",
    "    \"\"\"Segmentation generator\"\"\"\n",
    "    \n",
    "    for filename in files:\n",
    "        img = io.imread(filename)\n",
    "        yield img\n",
    "\n",
    "nuc_mask_generator = segmentation_generator(nuc_mask_file_names)\n",
    "nuc_reporter_generator = segmentation_generator(nuc_reporter_file_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## localizing the objects\n",
    "\n",
    "Now we use a utility function to localise the objects in the segmentation, and also apply anisotropic scaling (using the `scale` option, here the z-values are scaled by 2x). Note that we can also use scikit-image `regionprops` to calculate properties for each object, using the `properties` keyword:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "obj_from_arr = btrack.utils.segmentation_to_objects(stack, properties=('area', ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inspect the first object\n",
    "obj_from_arr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...Found no objects.\n"
     ]
    }
   ],
   "source": [
    "obj_from_generator = btrack.utils.segmentation_to_objects(\n",
    "    nuc_mask_generator, \n",
    "    intensity_image = nuc_reporter_generator,\n",
    "    properties = ('area', 'major_axis_length')\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_21395/3760781151.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# inspect the first object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mobj_from_generator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# inspect the first object\n",
    "obj_from_generator[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run btrack with the objects\n",
    "\n",
    "We will use the objects from the generator here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise a tracker session using a context manager\n",
    "with btrack.BayesianTracker() as tracker:\n",
    "\n",
    "    # configure the tracker using a config file\n",
    "    tracker.configure_from_file('../models/cell_config_AU565.json')\n",
    "    tracker.max_search_radius = 100\n",
    "\n",
    "    # append the objects to be tracked\n",
    "    tracker.append(obj_from_generator)\n",
    "\n",
    "    # set the volume\n",
    "    tracker.volume=((0, nuc_mask_stack.shape[2]), (0, nuc_mask_stack.shape[1]), (-1e5, 1e5))\n",
    "\n",
    "    # track them (in interactive mode)\n",
    "    tracker.track_interactive(step_size=200)\n",
    "\n",
    "    # generate hypotheses and run the global optimizer\n",
    "    tracker.optimize()\n",
    "\n",
    "    tracker.export(os.path.join(int_path, \"tracking\",well,field,\"results\",'tracking.h5'), obj_type='obj_type_1')\n",
    "\n",
    "    # get the tracks in a format for napari visualization\n",
    "    data, properties, graph = tracker.to_napari(ndim=2)\n",
    "    \n",
    "    #tracks = tracker.tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualize with napari\n",
    "\n",
    "Note that we also set the scale of the images here to account for the anisotropy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#viewer = napari.Viewer()\n",
    "#viewer = napari.view_image(img_p_stack, name = \"phase image\")\n",
    "\n",
    "viewer = napari.view_image(phase_stack, name = \"phase image\")\n",
    "viewer.add_labels(stack,  name='Segmentation')\n",
    "viewer.add_tracks(data, properties=properties, graph=graph, name='Tracks')\n",
    "\n",
    "napari.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Use the graph results to asign progeny and ancestors\n",
    "\n",
    "graph_filename = os.path.join(int_path, \"tracking\",well,field,\"results\",\"graph.csv\") graph_df = pd.DataFrame.from_dict(graph,orient='index', columns=['parent']) graph_df.reset_index(inplace=True) graph_df.rename(columns = {'index':'label'}) graph_df.to_csv(graph_filename,index=False)\n",
    "\n",
    " \n",
    "\n",
    "Create a new file tracks.csv with the following columns:\n",
    "label - a unique label of the track (label of markers, 16-bit positive value)\n",
    "begins - a zero-based temporal index of the frame in which the track begins\n",
    "ends - a zero-based temporal index of the frame in which the track ends\n",
    "parent - label of the parent track (0 is used when no parent is defined)\n",
    "length - The number of frames that the cell is identified in\n",
    "plateID - Character string of the plate's ID such as AU02001\n",
    "well - Character string of the well such as A1\n",
    "field - Integer of the image field within the well\n",
    "\n",
    "    \"\"\"Return an LBEP list describing the track lineage information.\n",
    "    Notes\n",
    "    -----\n",
    "    L : int\n",
    "        A unique label of the track (label of markers, 16-bit positive).\n",
    "    B : int\n",
    "        A zero-based temporal index of the frame in which the track begins.\n",
    "    E : int\n",
    "        A zero-based temporal index of the frame in which the track ends.\n",
    "    P : int\n",
    "        Label of the parent track (0 is used when no parent is defined).\n",
    "    R : int\n",
    "        Label of the root track.\n",
    "    G : int\n",
    "        Generational depth (from root).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking_filename = os.path.join(int_path,\"tracking\",well,field,\"results\",\"tracking.h5\")\n",
    "tracking = h5py.File(tracking_filename, 'r')\n",
    "lbepr = tracking_tracks['obj_type_1']['LBEPR'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set filter parameters\n",
    "min_track_length = 3\n",
    "\n",
    "tracking_filename = os.path.join(int_path,\"tracking\",well,field,\"results\",\"tracking.h5\")\n",
    "res_flt_filename = tracking_filename.replace(\"tracking.h5\",\"tracks.csv\")\n",
    "tracking = h5py.File(tracking_filename, 'r')\n",
    "lbepr = tracking_tracks['obj_type_1']['LBEPR'][:]\n",
    "lbepr_df = pd.DataFrame(lbepr, columns=['label','begins','ends','parent','root','depth'])\n",
    "lbepr_df['length'] = lbepr_df.ends - lbepr_df.begins + 1\n",
    "last_track = lbepr_df.ends.max()\n",
    "#check if object is a parent\n",
    "lbepr_df[\"is_parent\"] = lbepr_df['label'].isin(lbepr_df['parent'])\n",
    "lbepr_df['plateID'] = plateID\n",
    "lbepr_df['well'] = well\n",
    "lbepr_df['field'] = field.replace(\"field_\",\"\")\n",
    "#If filtered results do not exist, read in the res_track.txt file for the current field\n",
    "if not os.path.exists(res_flt_filename):\n",
    "    #Filter using the filter parameters\n",
    "    #remove short tracks that are not parents and are not in the last frame\n",
    "    tracks_flt = lbepr_df.query('length >= @min_track_length or is_parent or ends > (@last_track-@min_track_length)')\n",
    "    ##remove any track that appears after the first frame and doesn't have a parent\n",
    "    #tracks_flt = tracks_flt.query('not (begins > 1 & parent == 0)')\n",
    "    #write out the res_flt_track.txt file\n",
    "    tracks_flt.to_csv(res_flt_filename,index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_track_path = os.path.join(int_path,\"tracking\",well,field,\"results\")\n",
    "tracked_mask_filenames = sorted(glob.glob(mask_track_path+\"/mask*\"))[first_frame:last_frame]\n",
    "#condition on whether the filtered masks exist\n",
    "if not os.path.exists(tracked_mask_filenames[0].replace(\"results\",\"filtered_masks\")):\n",
    "   #read in the tracks file for this field    \n",
    "    res_flt_filename = os.path.join(int_path,\"tracking\",well,field,\"results\",\"tracks.csv\")\n",
    "    tracks = pd.read_csv(res_flt_filename) \n",
    "    #loop through the mask images in the field\n",
    "    for fn in tracked_mask_filenames:\n",
    "        #read in the mask image\n",
    "        im = io.imread(fn)\n",
    "        #replace any label that's not a cell with a 0 value\n",
    "        cell_labels = np.array([x if x in tracks.label.to_numpy()\n",
    "                                   else 0 for x in range(0, im.max()+1)])\n",
    "        im_filtered = cell_labels[im]\n",
    "        io.imsave(fn.replace(\"results\",\"filtered_masks\"), im_filtered.astype(np.int16), plugin='tifffile', check_contrast=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If the metadata exists, load it\n",
    "metadata_filename = os.path.join(data_path,plateID,\"metadata\",plateID+\".xlsx\")\n",
    "\n",
    "if os.path.exists(metadata_filename):\n",
    "    md_all = pd.read_excel(metadata_filename, engine='openpyxl', dtype={'Drug1Concentration': str, 'Drug2Concentration': str})\n",
    "    \n",
    "    #remove unwanted columns read in from the excel files\n",
    "    r = re.compile(\"Unnamed.*\")\n",
    "    columns_to_drop = list(filter(r.match, md_all.columns)) \n",
    "    metadata = md_all.drop(columns = columns_to_drop)\n",
    "    \n",
    "    #match metadata and data well labels format\n",
    "    metadata['row'] = [re.sub(r'[0-9]*', '', Well) for Well in metadata['Well']]\n",
    "    metadata['column'] = [re.sub(r'[A-Z]', '', Well) for Well in metadata['Well']]\n",
    "    metadata['column'] = [re.sub(r'\\A0', '', row) for row in metadata['column']]\n",
    "    metadata['well'] = metadata['row'] + metadata['column']\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyto_expansion = 5\n",
    "minutes_between_images = 30\n",
    "g1_threshold = .94\n",
    "neighborhood_nuclei_distance = 5\n",
    "neighborhood_radius_near = 20\n",
    "neighborhood_radius_medium = 45\n",
    "neighborhood_radius_far = 70\n",
    "\n",
    "def calc_G1_prop(x):\n",
    "    G1_count = x.value_counts()[1] #G1\n",
    "    G1_prop = G1_count/len(x)\n",
    "    return G1_prop\n",
    "\n",
    "l0_filename = os.path.join(data_path+plateID,\"Analysis\",pipeline_name,plateID+\"_\"+well+\"_\"+field+\"_level_0.csv\")\n",
    "\n",
    "#condition on whether the l1 file exists\n",
    "#if not os.path.exists(l0_filename.replace('level_0','level_1')):\n",
    "print(\"Pulling data from images \"+l0_filename.replace('_level_0.csv',''))\n",
    "filtered_mask_path = os.path.join(int_path,\"tracking\",well,field,\"filtered_masks\")\n",
    "tracked_mask_filenames = sorted(glob.glob(filtered_mask_path+\"/mask*\"))[first_frame:last_frame]\n",
    "img_gs_reg = io.imread(int_path+plateID+\"_G_\"+well+\"_\"+field.replace(\"field_\",\"\")+\"_reg_stack.tif\")[first_frame:last_frame]\n",
    "# iterate over the mask files\n",
    "results = []\n",
    "for i, fn in enumerate(tracked_mask_filenames):\n",
    "    #read in the mask image\n",
    "    masks = io.imread(fn)\n",
    "    #read in registered R images\n",
    "    reg_fn = fn.replace(\"filtered_masks\",\"reg\")\n",
    "    image = io.imread(reg_fn.replace(\"mask\",\"t\"))\n",
    "\n",
    "    #measure reporter intensity and nuclear morphology, texture\n",
    "    nuclei = measure.regionprops_table(masks, intensity_image=image,\n",
    "                                       properties=('label',\n",
    "                                                   'area','bbox_area','convex_area','centroid','eccentricity','equivalent_diameter','extent','feret_diameter_max','filled_area',\n",
    "                                                    'major_axis_length','minor_axis_length','moments_hu','perimeter','perimeter_crofton','solidity',\n",
    "                                                    'mean_intensity','max_intensity','min_intensity'))\n",
    "    #expand the masks to get cytoplasmic regions\n",
    "    nuclei_boundaries = segmentation.find_boundaries(masks, mode='thick')*masks\n",
    "    nuclei_expansions = segmentation.expand_labels(masks, cyto_expansion) - masks + nuclei_boundaries\n",
    "\n",
    "    # measure nuclear and cytoplasmic intensities and textures in the green channel\n",
    "    nuclei_g = measure.regionprops_table(masks, intensity_image=img_gs_reg[i],\n",
    "                                         properties=('label','centroid',\n",
    "                                                     'mean_intensity','max_intensity','min_intensity'))\n",
    "    nuclei_exp_g = measure.regionprops_table(nuclei_expansions, intensity_image=img_gs_reg[i],\n",
    "                                             properties=('label','centroid',\n",
    "                                                         'mean_intensity','max_intensity','min_intensity'))\n",
    "\n",
    "    # turn results into a dataframe\n",
    "    nuclei_data = pd.DataFrame(nuclei)\n",
    "    nuclei_data.rename(columns={col: 'Nuclei_'+pipeline_name+'_' +ch1_name+'_'+col  for col in nuclei_data.columns if col not in ['label']}, inplace=True)\n",
    "\n",
    "    nuclei_g_data = pd.DataFrame(nuclei_g)\n",
    "    nuclei_g_data.rename(columns={col: 'Nuclei_'+pipeline_name+'_' +ch2_name+'_'+col  for col in nuclei_g_data.columns if col not in ['label']}, inplace=True)\n",
    "\n",
    "    nuclei_exp_g_data = pd.DataFrame(nuclei_exp_g)\n",
    "    nuclei_exp_g_data.rename(columns={col: 'Cyto_'+pipeline_name+'_' +ch2_name+'_'+col  for col in nuclei_exp_g_data.columns if col not in ['label']}, inplace=True)\n",
    "\n",
    "    # recover the well and field values and add them to the dataframe\n",
    "    well = re.findall('/[A-Z][0-9]+/',reg_fn)[0]\n",
    "    well = re.sub('/','', well)\n",
    "    nuclei_data['well'] = well\n",
    "    field = re.findall('field_[0-9]+',reg_fn)[0]\n",
    "    field = int(re.sub('field_','', field))\n",
    "    nuclei_data['field'] = field\n",
    "    nuclei_data['slice'] = i\n",
    "    nuclei_data['elapsed_minutes'] = i*minutes_between_images #assumes time slice numbering starts at 1\n",
    "    elapsed_minutes = i*minutes_between_images #assumes time slice numbering starts at 1\n",
    "    day = np.floor(elapsed_minutes/(24*60)).astype(int)\n",
    "    hour = np.floor((elapsed_minutes-day*(24*60))/60).astype(int)\n",
    "    minute = np.floor(elapsed_minutes-day*(24*60)-hour*60).astype(int)\n",
    "    day = str(day).zfill(2)\n",
    "    hour = str(hour).zfill(2)\n",
    "    minute = str(minute).zfill(2)\n",
    "    nuclei_data['time_slice'] = day+\"d\"+hour+\"h\"+minute+\"m\"\n",
    "\n",
    "    #Calculate ratio of ch2 cyto to nuclei intensities\n",
    "    nuclei_exp_g_data['Cell_'+pipeline_name+'_' +ch2_name+'_mean_intensity_ratio'] = nuclei_exp_g_data['Cyto_'+pipeline_name+'_' +ch2_name+'_mean_intensity']/nuclei_g_data['Nuclei_'+pipeline_name+'_' +ch2_name+'_mean_intensity']\n",
    "    nuclei_exp_g_data['Cell_'+pipeline_name+'_' +ch2_name+'_max_intensity_ratio'] = nuclei_exp_g_data['Cyto_'+pipeline_name+'_' +ch2_name+'_max_intensity']/nuclei_g_data['Nuclei_'+pipeline_name+'_' +ch2_name+'_max_intensity']\n",
    "    nuclei_exp_g_data['Cell_'+pipeline_name+'_' +ch2_name+'_min_intensity_ratio'] = nuclei_exp_g_data['Cyto_'+pipeline_name+'_' +ch2_name+'_min_intensity']/nuclei_g_data['Nuclei_'+pipeline_name+'_' +ch2_name+'_min_intensity']\n",
    "\n",
    "    #label cell states based on the reporter ratio\n",
    "    nuclei_exp_g_data['cell_cycle_state'] = 'G1'\n",
    "    mask = nuclei_exp_g_data['Cell_'+pipeline_name+'_' +ch2_name+'_mean_intensity_ratio'] > g1_threshold\n",
    "    nuclei_exp_g_data.loc[mask, 'cell_cycle_state'] = 'S/G2'\n",
    "    nuclei_exp_g_data['cell_cycle_state_threshold'] = g1_threshold\n",
    "\n",
    "    #calculate the neighborhood density\n",
    "    nuclei_kd = spatial.KDTree(nuclei_data[['Nuclei_'+pipeline_name+'_NR_centroid-0','Nuclei_'+pipeline_name+'_NR_centroid-1']])\n",
    "    nuclei_data['neighborhood_'+str(neighborhood_radius_near)] = nuclei_kd.query_ball_point(nuclei_data[['Nuclei_'+pipeline_name+'_NR_centroid-0','Nuclei_'+pipeline_name+'_NR_centroid-1']],\n",
    "                                                                                            r = neighborhood_radius_near, return_sorted = True, return_length=True)\n",
    "    nuclei_data['neighborhood_'+str(neighborhood_radius_medium)] = nuclei_kd.query_ball_point(nuclei_data[['Nuclei_'+pipeline_name+'_NR_centroid-0','Nuclei_'+pipeline_name+'_NR_centroid-1']],\n",
    "                                                                                            r = neighborhood_radius_medium, return_sorted = True, return_length=True)\n",
    "    nuclei_data['neighborhood_'+str(neighborhood_radius_far)] = nuclei_kd.query_ball_point(nuclei_data[['Nuclei_'+pipeline_name+'_NR_centroid-0','Nuclei_'+pipeline_name+'_NR_centroid-1']],\n",
    "                                                                                            r = neighborhood_radius_far, return_sorted = True, return_length=True)\n",
    "\n",
    "    #merge the dataframes from the different channels\n",
    "    df = pd.merge(nuclei_data, nuclei_g_data, how=\"left\", on=[\"label\"])\n",
    "    df_all = pd.merge(df, nuclei_exp_g_data, how=\"left\", on=[\"label\"])\n",
    "\n",
    "    # append this image's dataframe to the results list\n",
    "    results.append(df_all)\n",
    "\n",
    "#concatenate all of the results from all images in the field\n",
    "l0_image = pd.concat(results)\n",
    "\n",
    "#join with the tracking results to get lineage, parent, frame length values\n",
    "tracks_filename = os.path.join(int_path,\"tracking\",well,\"field_\"+str(field),\"results/tracks.csv\")\n",
    "tracks = pd.read_csv(tracks_filename)\n",
    "l0 = pd.merge(l0_image, tracks, how=\"left\", on=[\"label\", \"well\", \"field\"])\n",
    "\n",
    "#label cell states based on the reporter ratio\n",
    "l0['cell_cycle_state'] = 'G1'\n",
    "mask = l0['Cell_'+pipeline_name+'_CC_mean_intensity_ratio'] > g1_threshold\n",
    "l0.loc[mask, 'cell_cycle_state'] = 'S/G2'\n",
    "\n",
    "if os.path.exists(metadata_filename):\n",
    "    #merge data and metadata on well values\n",
    "    l1= pd.merge(l0, metadata, how=\"left\", on=[\"well\"]).round(decimals=2)\n",
    "    l1['treatment'] =  l1['Drug1']+'_'+l1['Drug1Concentration']+'_'+l1['Drug2']+'_'+l1['Drug2Concentration']\n",
    "    #filter out first 9 slices\n",
    "#        l1 = l1[l1['slice'] > 9]\n",
    "    print(\"Writing \"+l0_filename.replace('level_0','level_1') + \" to disk\")\n",
    "    l1.to_csv(l0_filename.replace('level_0','level_1'), index = False)\n",
    "    #summarize to image level\n",
    "    l2 = l1.groupby(['plateID','well','field', 'time_slice', 'elapsed_minutes','Drug1','Drug1Concentration', 'Drug2', 'Drug2Concentration', 'treatment', 'cell_cycle_state_threshold']).agg(\n",
    "        n = ('plateID', 'size'),\n",
    "        length=('length', 'mean'),\n",
    "        Nuclei_CBn_NR_area=('Nuclei_CBn_NR_area', 'mean'),\n",
    "        Nuclei_CBn_CC_mean_intensity=('Nuclei_CBn_CC_mean_intensity', 'mean'),\n",
    "        Cyto_CBn_CC_mean_intensity=('Cyto_CBn_CC_mean_intensity', 'mean'),\n",
    "        Cell_CBn_CC_mean_intensity_ratio=('Cell_CBn_CC_mean_intensity_ratio', 'mean'),\n",
    "        Cell_CBn_CC_max_intensity_ratio=('Cell_CBn_CC_max_intensity_ratio', 'mean'),\n",
    "        Cell_CBn_CC_min_intensity_ratio=('Cell_CBn_CC_min_intensity_ratio', 'mean'),\n",
    "#            G1_proportion =('cell_cycle_state', calc_G1_prop),\n",
    "        neighborhood_20 = ('neighborhood_'+str(neighborhood_radius_near), 'mean'), #TODO figure out how to summarize with dynamic name\n",
    "        neighborhood_45 = ('neighborhood_'+str(neighborhood_radius_medium), 'mean'),\n",
    "        neighborhood_70 = ('neighborhood_'+str(neighborhood_radius_far), 'mean')\n",
    "    ).reset_index().round(decimals=2)\n",
    "    l2['cell_cycle_state_threshold'] = g1_threshold\n",
    "\n",
    "    print(\"Writing \"+l0_filename.replace('level_0','level_2') + \" to disk\")\n",
    "    l2.to_csv(l0_filename.replace('level_0','level_2'), index = False)\n",
    "else:\n",
    "    print(\"no metadata file for \"+plateID+\" so creating level 0 file\")\n",
    "    l0 = l0.round(decimals=2)\n",
    "    l0.to_csv(l0_filename, index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
