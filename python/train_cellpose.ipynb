{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7c7V4yEqDc_",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Running cellpose 2.0 on exacloud with a GPU\n",
    "\n",
    "<font size = 4>Cellpose 2.0 now allows you to train your own models in the GUI!\n",
    "\n",
    "This notebook allows you to load this **custom model** and run the model on your images with a GPU. \n",
    "\n",
    "In this notebook, you can also **train** a custom model using your labels (`_seg.npy`) files, or other labels as `_masks.tif` files. If you already have a trained model, skip this part of the notebook.\n",
    "\n",
    "For more details on cellpose 2.0 check out the [paper](https://www.biorxiv.org/content/10.1101/2022.04.01.486764v1) or the [talk](https://www.youtube.com/watch?v=3ydtAhfq6H0).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IvyuR08OZfw4"
   },
   "source": [
    "# Setup\n",
    "\n",
    "We will first check the GPU is working, and mount google drive to get your models and images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e2cBEO1PLuO7"
   },
   "source": [
    "Check CUDA version and that GPU is working in cellpose and import other libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tt8hgC7rniP8",
    "outputId": "677fa3d0-952f-4490-f5bb-4ef1ad0b0469"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> GPU activated? YES\n"
     ]
    }
   ],
   "source": [
    "#!nvcc --version\n",
    "#!nvidia-smi\n",
    "\n",
    "import os, shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cellpose import core, utils, io, models, metrics\n",
    "from glob import glob\n",
    "from natsort import natsorted\n",
    "\n",
    "\n",
    "use_GPU = core.use_gpu()\n",
    "yn = ['NO', 'YES']\n",
    "print(f'>>> GPU activated? {yn[use_GPU]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VfE75htF0l84"
   },
   "source": [
    "# Train model on manual annotations\n",
    "\n",
    "Fill out the form below with the paths to your data and the parameters to start training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lLdKNWQ4jxy5"
   },
   "source": [
    "## Training parameters\n",
    "\n",
    "<font size = 4> **Paths for training, predictions and results**\n",
    "\n",
    "\n",
    "<font size = 4>**`train_dir:`, `test_dir`:** These are the paths to your folders train_dir (with images and masks of training images) and test_dir (with images and masks of test images). You can leave the test_dir blank, but it's recommended to have some test images to check the model's performance. To find the paths of the folders containing the respective datasets, go to your Files on the left of the notebook, navigate to the folder containing your files and copy the path by right-clicking on the folder, **Copy path** and pasting it into the right box below.\n",
    "\n",
    "<font size = 4>**`initial_model`:** Choose a model from the cellpose [model zoo](https://cellpose.readthedocs.io/en/latest/models.html#model-zoo) to start from.\n",
    "\n",
    "<font size = 4>**`model_name`**: Enter the path where your model will be saved once trained (for instance your result folder).\n",
    "\n",
    "<font size = 4>**Training parameters**\n",
    "\n",
    "<font size = 4>**`number_of_epochs`:** Input how many epochs (rounds) the network will be trained. At least 100 epochs are recommended, but sometimes 250 epochs are necessary, particularly from scratch. **Default value: 100**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XQI4aUxCjz3n",
    "outputId": "804d0459-b120-4298-9b4c-87a9ca26401c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default advanced parameters enabled\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#@markdown ###Path to images and masks:\n",
    "data_path = \"/home/exacloud/gscratch/HeiserLab/images/cellpose_CtcK_HCC1143\"\n",
    "train_dir = os.path.join(data_path, \"train\") #@param {type:\"string\"}\n",
    "test_dir = os.path.join(data_path, \"test\") #@param {type:\"string\"}\n",
    "#Define where the patch file will be saved\n",
    "base = \"/content\"\n",
    "\n",
    "# model name and path\n",
    "#@markdown ###Name of the pretrained model to start from and new model name:\n",
    "from cellpose import models\n",
    "initial_model_name = \"LC2\" #@param ['cyto','nuclei','tissuenet','livecell','cyto2','CP','CPx','TN1','TN2','TN3','LC1','LC2','LC3','LC4','scratch']\n",
    "model_name = \"Ctc\"\n",
    "\n",
    "# other parameters for training.\n",
    "#@markdown ###Training Parameters:\n",
    "#@markdown Number of epochs:\n",
    "n_epochs =  100#@param {type:\"number\"}\n",
    "\n",
    "Channel_to_use_for_training = \"Green\" #@param [\"Grayscale\", \"Blue\", \"Green\", \"Red\"]\n",
    "\n",
    "# @markdown ###If you have a secondary channel that can be used for training, for instance nuclei, choose it here:\n",
    "\n",
    "Second_training_channel= \"Red\" #@param [\"Grayscale\", \"Blue\", \"Green\", \"Red\"]\n",
    "\n",
    "\n",
    "#@markdown ###Advanced Parameters\n",
    "\n",
    "Use_Default_Advanced_Parameters = True #@param {type:\"boolean\"}\n",
    "#@markdown ###If not, please input:\n",
    "learning_rate = 0.1 #@param {type:\"number\"}\n",
    "weight_decay = 0.0001 #@param {type:\"number\"}\n",
    "\n",
    "if (Use_Default_Advanced_Parameters): \n",
    "  print(\"Default advanced parameters enabled\")\n",
    "  learning_rate = 0.1 \n",
    "  weight_decay = 0.0001\n",
    "  \n",
    "#here we check that no model with the same name already exist, if so delete\n",
    "model_path = os.path.join(train_dir,'models')\n",
    "if os.path.exists(model_path+'/'+model_name):\n",
    "  print(\"!! WARNING: \"+model_name+\" already exists and will be deleted in the following cell !!\")\n",
    "  \n",
    "if len(test_dir) == 0:\n",
    "  test_dir = None\n",
    "\n",
    "# Here we match the channel to number\n",
    "if Channel_to_use_for_training == \"Grayscale\":\n",
    "  chan = 0\n",
    "elif Channel_to_use_for_training == \"Blue\":\n",
    "  chan = 3\n",
    "elif Channel_to_use_for_training == \"Green\":\n",
    "  chan = 2\n",
    "elif Channel_to_use_for_training == \"Red\":\n",
    "  chan = 1\n",
    "\n",
    "\n",
    "if Second_training_channel == \"Blue\":\n",
    "  chan2 = 3\n",
    "elif Second_training_channel == \"Green\":\n",
    "  chan2 = 2\n",
    "elif Second_training_channel == \"Red\":\n",
    "  chan2 = 1\n",
    "elif Second_training_channel == \"None\":\n",
    "  chan2 = 0\n",
    "\n",
    "if initial_model=='scratch':\n",
    "  initial_model = 'None'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_8SDv9XztBgb"
   },
   "source": [
    "Here's what the command to train would be on the command line -- make sure if you run this locally to correct the paths for your local computer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3JRxBPmatrK7"
   },
   "source": [
    "## Train new model\n",
    "\n",
    "Using settings from form above, train the model on images and labels in \"train\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XcYskYudMajM",
    "outputId": "ed4dce67-190e-4d52-9a70-bcbc76be4b65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-09 11:52:06,251 [INFO] WRITING LOG OUTPUT TO /home/users/dane/.cellpose/run.log\n",
      "2022-06-09 11:52:06,258 [INFO] >>>> loading model /home/exacloud/gscratch/HeiserLab/images/cellpose_CtcK_HCC1143/train/models/Ctc\n",
      "2022-06-09 11:52:08,310 [INFO] ** TORCH CUDA version installed and working. **\n",
      "2022-06-09 11:52:08,311 [INFO] >>>> using GPU\n",
      "2022-06-09 11:52:11,804 [INFO] >>>> model diam_mean =  35.000 (ROIs rescaled to this size during training)\n",
      "2022-06-09 11:52:11,806 [INFO] >>>> model diam_labels =  32.279 (mean diameter of training ROIs)\n",
      "2022-06-09 11:52:11,890 [INFO] not all flows are present, running flow generation for all images\n",
      "2022-06-09 11:52:13,849 [INFO] 8 / 8 images in /home/exacloud/gscratch/HeiserLab/images/cellpose_CtcK_HCC1143/train folder have labels\n",
      "2022-06-09 11:52:15,009 [INFO] computing flows for labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:03<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-09 11:52:18,933 [INFO] >>>> median diameter set to = 35\n",
      "2022-06-09 11:52:18,934 [INFO] >>>> mean of training label mask diameters (saved to model) 31.828\n",
      "2022-06-09 11:52:19,023 [INFO] >>>> training network with 2 channel input <<<<\n",
      "2022-06-09 11:52:19,024 [INFO] >>>> LR: 0.10000, batch_size: 8, weight_decay: 0.00010\n",
      "2022-06-09 11:52:19,026 [INFO] >>>> ntrain = 8\n",
      "2022-06-09 11:52:19,136 [INFO] >>>> nimg_per_epoch = 8\n",
      "2022-06-09 11:52:24,133 [INFO] Epoch 0, Time  5.1s, Loss 0.5519, LR 0.0000\n",
      "2022-06-09 11:52:24,387 [INFO] saving network parameters to /home/exacloud/gscratch/HeiserLab/images/cellpose_CtcK_HCC1143/train/models/Ctc\n",
      "2022-06-09 11:52:25,631 [INFO] Epoch 5, Time  6.6s, Loss 0.5836, LR 0.0556\n",
      "2022-06-09 11:52:26,707 [INFO] Epoch 10, Time  7.7s, Loss 0.4176, LR 0.1000\n",
      "2022-06-09 11:52:28,832 [INFO] Epoch 20, Time  9.8s, Loss 0.3946, LR 0.1000\n",
      "2022-06-09 11:52:30,954 [INFO] Epoch 30, Time 11.9s, Loss 0.4530, LR 0.1000\n",
      "2022-06-09 11:52:33,067 [INFO] Epoch 40, Time 14.0s, Loss 0.5389, LR 0.1000\n",
      "2022-06-09 11:52:35,187 [INFO] Epoch 50, Time 16.2s, Loss 0.4068, LR 0.1000\n",
      "2022-06-09 11:52:37,331 [INFO] Epoch 60, Time 18.3s, Loss 0.4003, LR 0.1000\n",
      "2022-06-09 11:52:39,383 [INFO] Epoch 70, Time 20.4s, Loss 0.4256, LR 0.1000\n",
      "2022-06-09 11:52:41,516 [INFO] Epoch 80, Time 22.5s, Loss 0.3989, LR 0.1000\n",
      "2022-06-09 11:52:43,648 [INFO] Epoch 90, Time 24.6s, Loss 0.3918, LR 0.1000\n",
      "2022-06-09 11:52:45,566 [INFO] saving network parameters to /home/exacloud/gscratch/HeiserLab/images/cellpose_CtcK_HCC1143/train/models/Ctc\n"
     ]
    }
   ],
   "source": [
    "initial_model_path = os.path.join(data_path, \"train\",\"models\",initial_model_name) #@param {type:\"string\"}\n",
    "#when updating a trained model, use it as both the initial model and the new model\n",
    "#comment out this line when the initial model is from the cellose zoo\n",
    "initial_model_path = os.path.join(data_path, \"train\",\"models\",model_name) #@param {type:\"string\"}\n",
    "\n",
    "# start logger (to see training across epochs)\n",
    "logger = io.logger_setup()\n",
    "\n",
    "# declare model\n",
    "model = models.CellposeModel(gpu=True, \n",
    "                             pretrained_model=initial_model_path,\n",
    "                            net_avg = True,\n",
    "                            diam_mean = 35)\n",
    "# set channels\n",
    "channels = [chan, chan2]\n",
    "\n",
    "# get files\n",
    "output = io.load_train_test_data(train_dir, mask_filter='_seg.npy')\n",
    "train_data, train_labels, _, test_data, test_labels, _ = output\n",
    "\n",
    "new_model_path = model.train(train_data, train_labels, \n",
    "                              #test_data=test_data,\n",
    "                              #test_labels=test_labels,\n",
    "                              channels=channels,\n",
    "                              save_path=train_dir, \n",
    "                              n_epochs=n_epochs,\n",
    "                              learning_rate=learning_rate, \n",
    "                              weight_decay=weight_decay, \n",
    "                              nimg_per_epoch=8,\n",
    "                              model_name=model_name)\n",
    "\n",
    "# diameter of labels in training images\n",
    "diam_labels = model.diam_labels.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KbVIZbNk5hgR"
   },
   "source": [
    "# Use custom model to segment images\n",
    "\n",
    "Take custom trained model from above to segment images in image_cache\n",
    "\n",
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "cellView": "form",
    "id": "vDu4Ixjo588O"
   },
   "outputs": [],
   "source": [
    "# model name and path\n",
    "\n",
    "#@markdown ###Custom model path (full path):\n",
    "model_path = os.path.join(data_path, \"train\",\"models\",model_name) #@param {type:\"string\"}\n",
    "\n",
    "#@markdown ###Path to images:\n",
    "\n",
    "dir = os.path.join(data_path, \"images\") #@param {type:\"string\"}\n",
    "\n",
    "\n",
    "#@markdown ###Channel Parameters:\n",
    "\n",
    "Channel_to_use_for_segmentation = \"Green\" #@param [\"Grayscale\", \"Blue\", \"Green\", \"Red\"]\n",
    "\n",
    "# @markdown If you have a secondary channel that can be used, for instance nuclei, choose it here:\n",
    "\n",
    "Second_segmentation_channel= \"Red\" #@param [\"None\", \"Blue\", \"Green\", \"Red\"]\n",
    "\n",
    "\n",
    "# Here we match the channel to number\n",
    "if Channel_to_use_for_segmentation == \"Grayscale\":\n",
    "  chan = 0\n",
    "elif Channel_to_use_for_segmentation == \"Blue\":\n",
    "  chan = 3\n",
    "elif Channel_to_use_for_segmentation == \"Green\":\n",
    "  chan = 2\n",
    "elif Channel_to_use_for_segmentation == \"Red\":\n",
    "  chan = 1\n",
    "\n",
    "\n",
    "if Second_segmentation_channel == \"Blue\":\n",
    "  chan2 = 3\n",
    "elif Second_segmentation_channel == \"Green\":\n",
    "  chan2 = 2\n",
    "elif Second_segmentation_channel == \"Red\":\n",
    "  chan2 = 1\n",
    "elif Second_segmentation_channel == \"None\":\n",
    "  chan2 = 0\n",
    "\n",
    "#@markdown ### Segmentation parameters:\n",
    "\n",
    "#@markdown diameter of cells (set to zero to use diameter from training set):\n",
    "diameter =  0#@param {type:\"number\"}\n",
    "#@markdown threshold on flow error to accept a mask (set higher to get more cells, e.g. in range from (0.1, 3.0), OR set to 0.0 to turn off so no cells discarded):\n",
    "flow_threshold = 0.4 #@param {type:\"slider\", min:0.0, max:3.0, step:0.1}\n",
    "#@markdown threshold on cellprob output to seed cell masks (set lower to include more pixels or higher to include fewer, e.g. in range from (-6, 6)):\n",
    "cellprob_threshold=0 #@param {type:\"slider\", min:-6, max:6, step:1}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QN3rdsfMBc_8"
   },
   "source": [
    "## run a model on a subset of the images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gCcbs722BYd0",
    "outputId": "b7de466b-4e7a-4585-b1d7-c282593b3fab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-09 11:53:00,627 [INFO] >>>> loading model /home/exacloud/gscratch/HeiserLab/images/cellpose_CtcK_HCC1143/train/models/Ctc\n",
      "2022-06-09 11:53:00,629 [INFO] ** TORCH CUDA version installed and working. **\n",
      "2022-06-09 11:53:00,632 [INFO] >>>> using GPU\n",
      "2022-06-09 11:53:00,791 [INFO] >>>> model diam_mean =  35.000 (ROIs rescaled to this size during training)\n",
      "2022-06-09 11:53:00,792 [INFO] >>>> model diam_labels =  31.828 (mean diameter of training ROIs)\n",
      "2022-06-09 11:53:00,804 [INFO] 0%|          | 0/30 [00:00<?, ?it/s]\n",
      "2022-06-09 11:53:02,451 [INFO] 3%|3         | 1/30 [00:01<00:47,  1.64s/it]\n",
      "2022-06-09 11:53:03,522 [INFO] 7%|6         | 2/30 [00:02<00:36,  1.31s/it]\n",
      "2022-06-09 11:53:04,341 [INFO] 10%|#         | 3/30 [00:03<00:29,  1.08s/it]\n",
      "2022-06-09 11:53:05,248 [INFO] 13%|#3        | 4/30 [00:04<00:26,  1.01s/it]\n",
      "2022-06-09 11:53:06,145 [INFO] 17%|#6        | 5/30 [00:05<00:24,  1.03it/s]\n",
      "2022-06-09 11:53:06,766 [INFO] 20%|##        | 6/30 [00:05<00:20,  1.17it/s]\n",
      "2022-06-09 11:53:07,403 [INFO] 23%|##3       | 7/30 [00:06<00:17,  1.28it/s]\n",
      "2022-06-09 11:53:08,028 [INFO] 27%|##6       | 8/30 [00:07<00:16,  1.37it/s]\n",
      "2022-06-09 11:53:08,739 [INFO] 30%|###       | 9/30 [00:07<00:15,  1.38it/s]\n",
      "2022-06-09 11:53:09,512 [INFO] 33%|###3      | 10/30 [00:08<00:14,  1.35it/s]\n",
      "2022-06-09 11:53:10,470 [INFO] 37%|###6      | 11/30 [00:09<00:15,  1.24it/s]\n",
      "2022-06-09 11:53:11,788 [INFO] 40%|####      | 12/30 [00:10<00:17,  1.04it/s]\n",
      "2022-06-09 11:53:12,706 [INFO] 43%|####3     | 13/30 [00:11<00:16,  1.05it/s]\n",
      "2022-06-09 11:53:13,590 [INFO] 47%|####6     | 14/30 [00:12<00:14,  1.08it/s]\n",
      "2022-06-09 11:53:14,416 [INFO] 50%|#####     | 15/30 [00:13<00:13,  1.11it/s]\n",
      "2022-06-09 11:53:15,321 [INFO] 53%|#####3    | 16/30 [00:14<00:12,  1.11it/s]\n",
      "2022-06-09 11:53:16,504 [INFO] 57%|#####6    | 17/30 [00:15<00:12,  1.01it/s]\n",
      "2022-06-09 11:53:17,307 [INFO] 60%|######    | 18/30 [00:16<00:11,  1.07it/s]\n",
      "2022-06-09 11:53:18,334 [INFO] 63%|######3   | 19/30 [00:17<00:10,  1.04it/s]\n",
      "2022-06-09 11:53:19,539 [INFO] 67%|######6   | 20/30 [00:18<00:10,  1.03s/it]\n",
      "2022-06-09 11:53:20,425 [INFO] 70%|#######   | 21/30 [00:19<00:08,  1.01it/s]\n",
      "2022-06-09 11:53:21,745 [INFO] 73%|#######3  | 22/30 [00:20<00:08,  1.09s/it]\n",
      "2022-06-09 11:53:22,721 [INFO] 77%|#######6  | 23/30 [00:21<00:07,  1.05s/it]\n",
      "2022-06-09 11:53:23,609 [INFO] 80%|########  | 24/30 [00:22<00:06,  1.00s/it]\n",
      "2022-06-09 11:53:24,519 [INFO] 83%|########3 | 25/30 [00:23<00:04,  1.02it/s]\n",
      "2022-06-09 11:53:25,485 [INFO] 87%|########6 | 26/30 [00:24<00:03,  1.03it/s]\n",
      "2022-06-09 11:53:26,911 [INFO] 90%|######### | 27/30 [00:26<00:03,  1.11s/it]\n",
      "2022-06-09 11:53:27,924 [INFO] 93%|#########3| 28/30 [00:27<00:02,  1.08s/it]\n",
      "2022-06-09 11:53:29,206 [INFO] 97%|#########6| 29/30 [00:28<00:01,  1.14s/it]\n",
      "2022-06-09 11:53:30,465 [INFO] 100%|##########| 30/30 [00:29<00:00,  1.18s/it]\n",
      "2022-06-09 11:53:30,467 [INFO] 100%|##########| 30/30 [00:29<00:00,  1.01it/s]\n"
     ]
    }
   ],
   "source": [
    "# gets image files in dir (ignoring image files ending in _masks)\n",
    "files = io.get_image_files(dir, '_masks', imf = \"r_and_p_img\")\n",
    "#print(files)\n",
    "images = [io.imread(f) for f in files]\n",
    "\n",
    "# declare model\n",
    "model = models.CellposeModel(gpu=True, \n",
    "                             pretrained_model=model_path)\n",
    "\n",
    "# use model diameter\n",
    "diameter = model.diam_labels \n",
    "\n",
    "# run model on test images\n",
    "masks, flows, styles = model.eval(images, \n",
    "                                  channels=[chan, chan2],\n",
    "                                  diameter=diameter,\n",
    "                                  flow_threshold=flow_threshold,\n",
    "                                  cellprob_threshold=cellprob_threshold\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qj5AIZ825o7P"
   },
   "source": [
    "## save output to *_seg.npy\n",
    "\n",
    "save images and mask labels combined in numpy arrays with \"_img_seg.npy\" suffixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "qc7EWe_f5oEH"
   },
   "outputs": [],
   "source": [
    "from cellpose import io\n",
    "\n",
    "io.masks_flows_to_seg(images, \n",
    "                      masks, \n",
    "                      flows, \n",
    "                      diameter*np.ones(len(masks)), \n",
    "                      files, \n",
    "                      channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "run_cellpose_2.0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
