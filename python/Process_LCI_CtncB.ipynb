{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6a8e734-b8d6-4d70-a4f8-c8e5d1a31550",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#setup libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, re, glob, sys\n",
    "from skimage import io, morphology, measure\n",
    "from skimage.registration import phase_cross_correlation\n",
    "from cellpose import models\n",
    "from scipy import spatial, ndimage\n",
    "from PIL import Image\n",
    "import tifffile\n",
    "import btrack\n",
    "import h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4a22418-0891-408d-bedb-1e5fb27427ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_name = \"CntB\" #cellpose trained nuclear and cell segmentation, btrack tracking\n",
    "ch1_name = 'NR'\n",
    "ch2_name = 'CC'\n",
    "data_path = '/home/exacloud/gscratch/HeiserLab/images/'\n",
    "data_path = '/home/groups/heiserlab_genomics/home/dane/CellTracking/images/'\n",
    "def in_ipython():\n",
    "    try:\n",
    "        return __IPYTHON__\n",
    "    except NameError:\n",
    "        return False\n",
    "if in_ipython():\n",
    "    cellline = \"HCC1143nlc\"\n",
    "    plateID = 'HC01701'\n",
    "    well_index = 8\n",
    "    debugging_flag = False\n",
    "else:\n",
    "    cellline = sys.argv[3]\n",
    "    plateID = sys.argv[1]\n",
    "    well_index = int(sys.argv[2])\n",
    "    debugging_flag = False\n",
    "\n",
    "output_path = os.path.join(data_path+plateID,\"Analysis\",pipeline_name,\"intermediate_files/\")\n",
    "registered_stacks_path = os.path.join(data_path+plateID,\"Analysis\",\"registered_stacks\")\n",
    "transformation_path = os.path.join(registered_stacks_path,\"transformations\")\n",
    "tracking_path = os.path.join(output_path,'tracking/')\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "            \n",
    "#Assume 24 well plate, select well using the index\n",
    "well_list = (\"A1\", \"A2\",\"A3\", \"A4\", \"A5\", \"A6\",\n",
    "            \"B1\", \"B2\",\"B3\", \"B4\", \"B5\", \"B6\",\n",
    "            \"C1\", \"C2\",\"C3\", \"C4\", \"C5\", \"C6\",\n",
    "            \"D1\", \"D2\",\"D3\", \"D4\", \"D5\", \"D6\",)\n",
    "\n",
    "#set up for 24  well plate, select well using the index\n",
    "#well_lists = (['A' + str(i) for i in list(range(1, 7))],\n",
    "#             ['B' + str(i) for i in list(range(1, 7))],\n",
    "#             ['C' + str(i) for i in list(range(1, 7))],\n",
    "#             ['D' + str(i) for i in list(range(1, 7))])\n",
    "#well_list = [item for sublist in well_lists for item in sublist]\n",
    "#well = well_list[well_index-1]\n",
    "\n",
    "#set up for 96  well plate, select well using the index\n",
    "well_lists = (['A' + str(i) for i in list(range(1, 13))],\n",
    "             ['B' + str(i) for i in list(range(1, 13))],\n",
    "             ['C' + str(i) for i in list(range(1, 13))],\n",
    "             ['D' + str(i) for i in list(range(1, 13))],\n",
    "             ['E' + str(i) for i in list(range(1, 13))],\n",
    "             ['F' + str(i) for i in list(range(1, 13))],\n",
    "             ['G' + str(i) for i in list(range(1, 13))],\n",
    "             ['H' + str(i) for i in list(range(1, 13))])\n",
    "#well_list = [item for sublist in well_lists for item in sublist] #uncomment to handle 96 well plates\n",
    "well = well_list[well_index-1]\n",
    "if os.path.exists(os.path.join(data_path,plateID,well)):\n",
    "    subdirectories = sorted(glob.glob(os.path.join(data_path,plateID,well,\"field_[1-9]\")))\n",
    "else:\n",
    "    P_registered_stacks = sorted(glob.glob(os.path.join(data_path,plateID,\"Analysis\",\"registered_stacks\",plateID+\"_P_\"+well+\"*\")))\n",
    "    subdirectories = []\n",
    "    for stack_name in P_registered_stacks:\n",
    "        field_str = re.findall(\"_[1-9]_\",stack_name)[0]\n",
    "        field_num = re.sub(\"_\", \"\", field_str)\n",
    "        subdirectories.append(os.path.join(data_path,plateID,well,\"field_\"+field_num))\n",
    "\n",
    "if debugging_flag:\n",
    "    subdirectories = subdirectories[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c9e723-6538-47f0-b7ff-b4390800aa14",
   "metadata": {},
   "source": [
    "#### Register the image stacks\n",
    "If there is a registered red channel stack skip this step, otherwise:  \n",
    "Load the red, green and phase images  \n",
    "Delete images from any time slice that does not have a complete set of images  \n",
    "Rescale the fluorescent images from 12 to 8 bits  \n",
    "Calculate the transformations needed to register the red stack, correcting the translation only  \n",
    "Store the registration transformations  \n",
    "Use the transformations to register all three stacks  \n",
    "Save the registered stacks as 16 bit images  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee281d51-5b59-49a1-9dcb-a4b98aa9b07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for subdir in subdirectories:\n",
    "    field = re.findall(\"field_[1-9]\",subdir)[0]\n",
    "    field_num = re.findall(\"[0-9]\", field)[0]\n",
    "    reg_filename = os.path.join(registered_stacks_path,plateID+\"_R_\"+well+\"_\"+field_num+\"_reg_stack.tif\")\n",
    "    # Only process the field-level image files if registered stacks are missing\n",
    "    if not np.logical_and(np.logical_and(os.path.exists(reg_filename),os.path.exists(reg_filename.replace(\"_R_\", \"_P_\"))),os.path.exists(reg_filename.replace(\"_R_\", \"_G_\"))):\n",
    "        sys.stdout.write(\"Gathering image stacks for \"+subdir+\"\\n\")\n",
    "        #load and prepare red, green and phase channels. Scale for 8 bits but these are uint16 data types\n",
    "        r_data_paths = glob.glob(os.path.join(subdir,\"*_R_*m.tif\"))\n",
    "        r_time_slices = set()\n",
    "        for data_paths in r_data_paths:\n",
    "            r_time_slices.add(re.findall(\"..d..h..m\", data_paths)[0])\n",
    "        g_data_paths = glob.glob(os.path.join(subdir,\"*_G_*m.tif\"))\n",
    "        g_time_slices = set()\n",
    "        for data_paths in g_data_paths:\n",
    "            g_time_slices.add(re.findall(\"..d..h..m\", data_paths)[0])\n",
    "        p_data_paths = glob.glob(os.path.join(subdir,\"*_P_*m.tif\"))\n",
    "        p_time_slices = set()\n",
    "        for data_paths in p_data_paths:\n",
    "            p_time_slices.add(re.findall(\"..d..h..m\", data_paths)[0])\n",
    "        complete_time_slices = r_time_slices & g_time_slices & p_time_slices\n",
    "        r_data_paths_c = []\n",
    "        g_data_paths_c = []\n",
    "        p_data_paths_c = []\n",
    "        for time_slice in complete_time_slices:\n",
    "            r_data_paths_c.append(os.path.join(data_path+plateID,well,field,plateID+\"_R_\"+well+\"_\"+field_num+\"_\"+time_slice+\".tif\"))\n",
    "            g_data_paths_c.append(os.path.join(data_path+plateID,well,field,plateID+\"_G_\"+well+\"_\"+field_num+\"_\"+time_slice+\".tif\"))\n",
    "            p_data_paths_c.append(os.path.join(data_path+plateID,well,field,plateID+\"_P_\"+well+\"_\"+field_num+\"_\"+time_slice+\".tif\"))\n",
    "        img_r_ic = io.imread_collection(r_data_paths_c) # 3 dimensions : frames x width x height\n",
    "        img_rs = np.stack(img_r_ic)\n",
    "\n",
    "        img_g_ic = io.imread_collection(g_data_paths_c) # 3 dimensions : frames x width x height\n",
    "        img_gs = np.stack(img_g_ic)\n",
    "\n",
    "        img_p_ic = io.imread_collection(p_data_paths_c) # 3 dimensions : frames x width x height\n",
    "        img_ps = np.stack(img_p_ic)\n",
    "        \n",
    "        #register using skimage skimage.registration phase_cross_correlation\n",
    "        shifts = np.zeros([img_ps.shape[0], 2])\n",
    "        img_rs_reg = img_rs\n",
    "        img_gs_reg = img_gs\n",
    "        img_ps_reg = img_ps\n",
    "        sys.stdout.write(\"calculating shifts\"+\"\\n\")\n",
    "        for i, image in enumerate(img_ps[range(img_ps.shape[0]-1)]): #loop through the first to the second to last image\n",
    "            shift, error, diffphase = phase_cross_correlation(image, img_ps[i+1], normalization=None, upsample_factor=4)\n",
    "            #print(str(i)+\" shift: \"+str(shift))\n",
    "            shifts[i+1] = shifts[i]+shift #make shifts absolute, based on first image\n",
    "            #print(str(i)+\" absolute shift: \"+str(shifts[i+1]))\n",
    "        sys.stdout.write(\"shifting image stacks\"+\"\\n\")\n",
    "        for i in range(img_ps.shape[0]):\n",
    "            img_rs_reg[i] = ndimage.shift(img_rs[i], shifts[i], order=3, mode='constant', cval=0, prefilter=True)\n",
    "            img_gs_reg[i] = ndimage.shift(img_gs[i], shifts[i], order=3, mode='constant', cval=0, prefilter=True)\n",
    "            img_ps_reg[i] = ndimage.shift(img_ps[i], shifts[i], order=3, mode='constant', cval=0, prefilter=True)\n",
    "            \n",
    "        if not os.path.exists(transformation_path):\n",
    "            os.makedirs(transformation_path, exist_ok=True)\n",
    "        np.save(os.path.join(transformation_path,plateID+\"_\"+well+\"_\"+field+\"_shifts.npy\"), shifts)\n",
    "\n",
    "        #assume transformations are in pixels and crop images to exclude areas that are outside of any registered image\n",
    "        x_axis_length = img_rs_reg.shape[2]\n",
    "        y_axis_length = img_rs_reg.shape[1]\n",
    "        \n",
    "        #crop each stack to the area that is common in all images after registration\n",
    "        #use the min and max values in the transformation stack to define the common active area \n",
    "        x_max = shifts[:,1].max().astype(\"int\")\n",
    "        x_min = shifts[:,1].min().astype(\"int\")\n",
    "        y_max = shifts[:,0].max().astype(\"int\")\n",
    "        y_min = shifts[:,0].min().astype(\"int\")\n",
    "        \n",
    "        #assume transformations are in pixels and crop images to exclude areas that are outside of any registered image\n",
    "        x_axis_length = img_rs_reg.shape[2]\n",
    "        y_axis_length = img_rs_reg.shape[1]\n",
    "        sys.stdout.write(\"Cropping to active areas for \"+subdir+\"\\n\")\n",
    "        \n",
    "        img_rs_reg_crop = img_rs_reg[:,np.max([0, y_max]):(y_axis_length+np.min([0,y_min])),np.max([0, x_max]):(x_axis_length+np.min([0,x_min]))]\n",
    "        img_gs_reg_crop = img_gs_reg[:,np.max([0, y_max]):(y_axis_length+np.min([0,y_min])),np.max([0, x_max]):(x_axis_length+np.min([0,x_min]))]\n",
    "        img_ps_reg_crop = img_ps_reg[:,np.max([0, y_max]):(y_axis_length+np.min([0,y_min])),np.max([0, x_max]):(x_axis_length+np.min([0,x_min]))]\n",
    "        sys.stdout.write(\"Saving stacks to disk for \"+subdir+\"\\n\")\n",
    "        io.imsave(reg_filename, img_rs_reg_crop.astype(np.int16), plugin='tifffile', check_contrast=False)\n",
    "        io.imsave(reg_filename.replace(\"_R_\",\"_G_\"), img_gs_reg_crop.astype(np.int16), plugin='tifffile', check_contrast=False)\n",
    "        io.imsave(reg_filename.replace(\"_R_\",\"_P_\"), img_ps_reg_crop.astype(np.int16), plugin='tifffile', check_contrast=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56165ee9-0033-4a66-9378-888133531030",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Segment the phase and nuclear fluorescent images using trained cellpose model  \n",
    "If mask files already exist, skip this step, otherwise:    \n",
    "Load the registered phase and red stack nuclear marker images  \n",
    "Segment cell outlines in the phase image \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0969bc58-1cc0-49fb-9cf6-e0386575cf18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with cell segmentation for HC01701 B2 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_loaded = False\n",
    "\n",
    "for subdir in subdirectories:\n",
    "    results = [] #collect results for one field in the well\n",
    "    field = re.findall(\"field_[1-9]\",subdir)[0]\n",
    "    field_num = re.findall(\"[0-9]\", field)[0]\n",
    "    reg_filename = os.path.join(registered_stacks_path,plateID+\"_R_\"+well+\"_\"+field_num+\"_reg_stack.tif\")\n",
    "    cell_mask_filename = os.path.join(output_path,plateID+\"_\"+well+\"_\"+field_num+\"_cell_masks.tif\")\n",
    "\n",
    "    if not os.path.exists(cell_mask_filename): #Only segment if no mask files\n",
    "        \n",
    "        if not model_loaded:\n",
    "            flow_threshold = .4\n",
    "            cellprob_threshold=0\n",
    "            c_min_size=400 \n",
    "            c_max_size = 10000\n",
    "            resample = True\n",
    "            # define CHANNELS to run segementation on\n",
    "            # grayscale=0, R=1, G=2, B=3\n",
    "            # channels = [cytoplasm, nucleus]\n",
    "            # if NUCLEUS channel does not exist, set the second channel to 0\n",
    "            # will use channel R = 1 as nuclear channel only\n",
    "            c_channels = [2,1]\n",
    "            n_channels = [0,0]\n",
    "            # DEFINE CELLPOSE MODELs\n",
    "            cell_model = models.CellposeModel(gpu=True, pretrained_model = \"/home/exacloud/gscratch/HeiserLab/images/cellpose_Ctc_\"+cellline+\"/train/models/Ctc\")\n",
    "            model_loaded = True\n",
    "            \n",
    "        sys.stdout.write(\"Start segmenting \"+plateID + \" \"+ well + \" \" + field+\"\\n\")\n",
    "        img_rs_reg = io.imread(reg_filename)\n",
    "        img_ps_reg = io.imread(reg_filename.replace('_R_', '_P_'))\n",
    "        \n",
    "        if debugging_flag:\n",
    "            img_rs_reg = img_rs_reg[0:10]\n",
    "            img_ps_reg = img_ps_reg[0:10]\n",
    "\n",
    "        cell_mask_images = []\n",
    "\n",
    "        for i in range(len(img_ps_reg)):\n",
    "            image = np.stack((img_rs_reg[i], img_ps_reg[i]))\n",
    "\n",
    "            # create cyto masks with cellpose \n",
    "            cell_masks, flows, styles = cell_model.eval(image,\n",
    "                                                        net_avg = True,\n",
    "                                                        flow_threshold=flow_threshold,\n",
    "                                                        cellprob_threshold=cellprob_threshold,\n",
    "                                                        channels=c_channels)\n",
    "\n",
    "            #Make a list of the filtered cell mask full size images \n",
    "            cell_mask_images.append(cell_masks)\n",
    "        io.imsave(cell_mask_filename, np.array(cell_mask_images, dtype = 'uint16'), plugin='tifffile', check_contrast=False)\n",
    "\n",
    "sys.stdout.write(\"done with cell segmentation for \"+plateID+\" \"+well+\" \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6aa020c2-a127-48d7-ba74-04afa496983e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copying registered P images to tracking directory/home/groups/heiserlab_genomics/home/dane/CellTracking/images/HC01701/Analysis/CntB/intermediate_files/tracking/ B2/field_1/reg\n",
      "copying cell masks images to tracking directory/home/groups/heiserlab_genomics/home/dane/CellTracking/images/HC01701/Analysis/CntB/intermediate_files/tracking/B2/field_1/cell_masks\n",
      "copying registered P images to tracking directory/home/groups/heiserlab_genomics/home/dane/CellTracking/images/HC01701/Analysis/CntB/intermediate_files/tracking/ B2/field_2/reg\n",
      "copying cell masks images to tracking directory/home/groups/heiserlab_genomics/home/dane/CellTracking/images/HC01701/Analysis/CntB/intermediate_files/tracking/B2/field_2/cell_masks\n",
      "copying registered P images to tracking directory/home/groups/heiserlab_genomics/home/dane/CellTracking/images/HC01701/Analysis/CntB/intermediate_files/tracking/ B2/field_3/reg\n",
      "copying cell masks images to tracking directory/home/groups/heiserlab_genomics/home/dane/CellTracking/images/HC01701/Analysis/CntB/intermediate_files/tracking/B2/field_3/cell_masks\n",
      "copying registered P images to tracking directory/home/groups/heiserlab_genomics/home/dane/CellTracking/images/HC01701/Analysis/CntB/intermediate_files/tracking/ B2/field_4/reg\n",
      "copying cell masks images to tracking directory/home/groups/heiserlab_genomics/home/dane/CellTracking/images/HC01701/Analysis/CntB/intermediate_files/tracking/B2/field_4/cell_masks\n"
     ]
    }
   ],
   "source": [
    "#Copy individual image and mask files to the tracking directories\n",
    "for subdir in subdirectories:\n",
    "    field = re.findall(\"field_[1-9]\",subdir)[0]\n",
    "    field_num = re.findall(\"[0-9]\", field)[0]\n",
    "    reg_filename = os.path.join(registered_stacks_path,plateID+\"_R_\"+well+\"_\"+field_num+\"_reg_stack.tif\")\n",
    "    c_mask_filename = os.path.join(output_path,plateID+\"_\"+well+\"_\"+field_num+\"_cell_masks.tif\")\n",
    "    tracking_path = os.path.join(output_path,'tracking/')\n",
    "    \n",
    "    if not os.path.exists(tracking_path+well+\"/\"+field+\"/cell_masks/\"):\n",
    "            os.makedirs(tracking_path+well+\"/\"+field+\"/cell_masks/\", exist_ok=True)\n",
    "    if not os.path.exists(tracking_path+well+\"/\"+field+\"/reg\"):\n",
    "            os.makedirs(tracking_path+well+\"/\"+field+\"/reg\", exist_ok=True)\n",
    "    if not os.path.exists(tracking_path+well+\"/\"+field+\"/results\"):\n",
    "            os.makedirs(tracking_path+well+\"/\"+field+\"/results\", exist_ok=True)\n",
    "    \n",
    "    #Only write files if image stacks exist and the individual files are not present\n",
    "    if os.path.exists(reg_filename.replace('_R_', '_P_')):\n",
    "        if not os.listdir(tracking_path+well+\"/\"+field+\"/reg\"):\n",
    "            sys.stdout.write(\"copying registered P images to tracking directory\"+tracking_path+\" \"+well+\"/\"+field+\"/reg\\n\")\n",
    "            #Use skimage to save individual images in the registered P image stack\n",
    "            im_s = io.imread(reg_filename.replace('_R_', '_P_'))\n",
    "            if debugging_flag:\n",
    "                im_s = im_s[0:10]\n",
    "\n",
    "            for i in range(len(im_s)):\n",
    "                io.imsave(tracking_path+well+\"/\"+field+\"/reg/\"+\"t%03.d.tif\"%i, im_s[i].astype(np.int16), plugin='tifffile', check_contrast=False)    # Open the mask stack:\n",
    "      \n",
    "    # Open the cell mask stack:\n",
    "    if os.path.exists(c_mask_filename):\n",
    "        if not os.listdir(tracking_path+well+\"/\"+field+\"/cell_masks\"):\n",
    "            sys.stdout.write(\"copying cell masks images to tracking directory\"+tracking_path+well+\"/\"+field+\"/cell_masks\\n\")\n",
    "            #Use skimage to save individual images in the registered RP image stack\n",
    "            im_s = io.imread(c_mask_filename)\n",
    "            if debugging_flag:\n",
    "                im_s = im_s[0:10]\n",
    "                \n",
    "            for i in range(len(im_s)):\n",
    "                io.imsave(tracking_path+well+\"/\"+field+\"/cell_masks/\"+\"mask%03.d.tif\"%i, im_s[i].astype(np.int16), plugin='tifffile', check_contrast=False)    # Open the mask stack:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e052aa9-95d2-454e-80b4-196cbcb806b3",
   "metadata": {},
   "source": [
    "#### Track the cells  \n",
    "Use the Bayesian tracker 'btrack' to track the cells  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7de640e4-73ba-4fee-a845-70ecaa259835",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2023/04/06 07:33:38 AM] Localizing objects from segmentation...\n",
      "[INFO][2023/04/06 07:33:38 AM] Found intensity_image data\n",
      "[INFO][2023/04/06 07:33:38 AM] Calculating weighted centroids using intensity_image\n",
      "[INFO][2023/04/06 07:34:45 AM] Objects are of type: <class 'dict'>\n",
      "[INFO][2023/04/06 07:34:47 AM] ...Found 194762 objects in 381 frames.\n",
      "[INFO][2023/04/06 07:34:47 AM] Loaded btrack: /home/exacloud/gscratch/HeiserLab/software/BayesianTracker/btrack/libs/libtracker.so\n",
      "[INFO][2023/04/06 07:34:47 AM] btrack (v0.5.0) library imported\n",
      "[INFO][2023/04/06 07:34:47 AM] Starting BayesianTracker session\n",
      "[INFO][2023/04/06 07:34:47 AM] Loading configuration file: ../models/cell_config_HCC1143.json\n",
      "[INFO][2023/04/06 07:34:47 AM] Objects are of type: <class 'list'>\n",
      "[INFO][2023/04/06 07:34:50 AM] Starting tracking... \n",
      "[INFO][2023/04/06 07:34:50 AM] Update using: ['VISUAL', 'MOTION']\n",
      "[INFO][2023/04/06 07:34:51 AM] Tracking objects in frames 0 to 99 (of 381)...\n",
      "[INFO][2023/04/06 07:34:58 AM]  - Timing (Bayesian updates: 30.00ms, Linking: 0.00ms)\n",
      "[INFO][2023/04/06 07:34:58 AM]  - Probabilities (Link: 1.00000, Lost: 1.00000)\n",
      "[INFO][2023/04/06 07:34:58 AM]  - Stats (Active: 394, Lost: 1198, Conflicts resolved: 1907)\n",
      "[INFO][2023/04/06 07:34:58 AM] Tracking objects in frames 100 to 199 (of 381)...\n",
      "[INFO][2023/04/06 07:35:19 AM]  - Timing (Bayesian updates: 80.00ms, Linking: 10.00ms)\n",
      "[INFO][2023/04/06 07:35:19 AM]  - Probabilities (Link: 1.00000, Lost: 0.99994)\n",
      "[INFO][2023/04/06 07:35:19 AM]  - Stats (Active: 579, Lost: 2515, Conflicts resolved: 3993)\n",
      "[INFO][2023/04/06 07:35:19 AM] Tracking objects in frames 200 to 299 (of 381)...\n",
      "[INFO][2023/04/06 07:36:02 AM]  - Timing (Bayesian updates: 150.00ms, Linking: 10.00ms)\n",
      "[INFO][2023/04/06 07:36:02 AM]  - Probabilities (Link: 1.00000, Lost: 1.00000)\n",
      "[INFO][2023/04/06 07:36:02 AM]  - Stats (Active: 704, Lost: 4830, Conflicts resolved: 7548)\n",
      "[INFO][2023/04/06 07:36:02 AM] Tracking objects in frames 300 to 381 (of 381)...\n",
      "[INFO][2023/04/06 07:36:42 AM]  - Timing (Bayesian updates: 160.00ms, Linking: 10.00ms)\n",
      "[INFO][2023/04/06 07:36:42 AM]  - Probabilities (Link: 1.00000, Lost: 0.99501)\n",
      "[INFO][2023/04/06 07:36:42 AM] SUCCESS.\n",
      "[INFO][2023/04/06 07:36:42 AM]  - Found 11370 tracks in 381 frames (in 0.0s)\n",
      "[INFO][2023/04/06 07:36:42 AM]  - Inserted 2289 dummy objects to fill tracking gaps\n",
      "[WARNING][2023/04/06 07:36:42 AM] `track_interactive` will be deprecated. Use `track` instead.\n",
      "[INFO][2023/04/06 07:36:42 AM] Starting tracking... \n",
      "[INFO][2023/04/06 07:36:42 AM] Update using: ['VISUAL', 'MOTION']\n",
      "[INFO][2023/04/06 07:36:42 AM] SUCCESS.\n",
      "[INFO][2023/04/06 07:36:42 AM]  - Found 11370 tracks in 381 frames (in 0.0s)\n",
      "[INFO][2023/04/06 07:36:42 AM]  - Inserted 2289 dummy objects to fill tracking gaps\n",
      "[INFO][2023/04/06 07:36:42 AM] Loading hypothesis model: cell_hypothesis\n",
      "[INFO][2023/04/06 07:36:42 AM] Calculating hypotheses (relax: True)...\n",
      "[INFO][2023/04/06 07:36:43 AM] Setting up constraints matrix for global optimisation...\n",
      "[INFO][2023/04/06 07:36:43 AM] Using GLPK options: {'tm_lim': 600000}...\n",
      "[INFO][2023/04/06 07:36:45 AM] Optimizing...\n",
      "[INFO][2023/04/06 07:37:21 AM] Optimization complete. (Solution: optimal)\n",
      "[INFO][2023/04/06 07:37:21 AM]  - Fates.FALSE_POSITIVE: 373 (of 11370)\n",
      "[INFO][2023/04/06 07:37:21 AM]  - Fates.LINK: 6004 (of 14345)\n",
      "[INFO][2023/04/06 07:37:21 AM]  - Fates.DIVIDE: 1187 (of 9218)\n",
      "[INFO][2023/04/06 07:37:21 AM]  - Fates.INITIALIZE_BORDER: 336 (of 835)\n",
      "[INFO][2023/04/06 07:37:21 AM]  - Fates.INITIALIZE_FRONT: 276 (of 314)\n",
      "[INFO][2023/04/06 07:37:21 AM]  - Fates.INITIALIZE_LAZY: 2007 (of 10221)\n",
      "[INFO][2023/04/06 07:37:21 AM]  - Fates.TERMINATE_BORDER: 412 (of 795)\n",
      "[INFO][2023/04/06 07:37:21 AM]  - Fates.TERMINATE_BACK: 805 (of 926)\n",
      "[INFO][2023/04/06 07:37:21 AM]  - Fates.TERMINATE_LAZY: 2589 (of 9649)\n",
      "[INFO][2023/04/06 07:37:21 AM]  - TOTAL: 57673 hypotheses\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLPK Integer Optimizer, v4.65\n",
      "45480 rows, 57673 columns, 101824 non-zeros\n",
      "57673 integer variables, all of which are binary\n",
      "Preprocessing...\n",
      "22740 rows, 57673 columns, 101824 non-zeros\n",
      "57673 integer variables, all of which are binary\n",
      "Scaling...\n",
      " A: min|aij| =  1.000e+00  max|aij| =  1.000e+00  ratio =  1.000e+00\n",
      "Problem data seem to be well scaled\n",
      "Constructing initial basis...\n",
      "Size of triangular part is 22740\n",
      "Solving LP relaxation...\n",
      "GLPK Simplex Optimizer, v4.65\n",
      "22740 rows, 57673 columns, 101824 non-zeros\n",
      "*     0: obj =   1.392158830e+05 inf =   0.000e+00 (25199)\n",
      "Perturbing LP to avoid stalling [489]...\n",
      "*  3262: obj =   1.068264205e+05 inf =   0.000e+00 (17573) 1\n",
      "*  6148: obj =   8.523925551e+04 inf =   0.000e+00 (12759) 6\n",
      "*  9413: obj =   6.182076485e+04 inf =   0.000e+00 (9784) 2\n",
      "* 12289: obj =   4.942010398e+04 inf =   0.000e+00 (7715) 6\n",
      "* 15331: obj =   4.097450818e+04 inf =   2.776e-16 (4616) 5\n",
      "* 18091: obj =   3.680138159e+04 inf =   4.567e-08 (1686) 15\n",
      "Removing LP perturbation [19494]...\n",
      "* 19494: obj =   3.655462531e+04 inf =   5.551e-17 (0) 7\n",
      "OPTIMAL LP SOLUTION FOUND\n",
      "Integer optimization begins...\n",
      "Long-step dual simplex will be used\n",
      "+ 19494: mip =     not found yet >=              -inf        (1; 0)\n",
      "+ 19521: >>>>>   3.656154291e+04 >=   3.655474575e+04 < 0.1% (10; 0)\n",
      "+ 19539: >>>>>   3.655488477e+04 >=   3.655479734e+04 < 0.1% (14; 1)\n",
      "+ 19560: >>>>>   3.655485431e+04 >=   3.655481839e+04 < 0.1% (14; 6)\n",
      "+ 19579: >>>>>   3.655484004e+04 >=   3.655482861e+04 < 0.1% (8; 17)\n",
      "+ 19590: mip =   3.655484004e+04 >=     tree is empty   0.0% (0; 43)\n",
      "INTEGER OPTIMAL SOLUTION FOUND\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2023/04/06 07:37:22 AM] Completed optimization with 5366 tracks\n",
      "[INFO][2023/04/06 07:37:22 AM] Opening HDF file: /home/groups/heiserlab_genomics/home/dane/CellTracking/images/HC01701/Analysis/CntB/intermediate_files/tracking/B2/field_1/results/tracking.h5...\n",
      "[INFO][2023/04/06 07:37:24 AM] Writing objects/obj_type_1\n",
      "[INFO][2023/04/06 07:37:25 AM] Writing labels/obj_type_1\n",
      "[INFO][2023/04/06 07:37:25 AM] Loading objects/obj_type_1 (194762, 5) (194762 filtered: None)\n",
      "[INFO][2023/04/06 07:37:27 AM] Writing properties/obj_type_1/area (194762,)\n",
      "[INFO][2023/04/06 07:37:27 AM] Writing properties/obj_type_1/major_axis_length (194762,)\n",
      "[INFO][2023/04/06 07:37:27 AM] Writing properties/obj_type_1/minor_axis_length (194762,)\n",
      "[INFO][2023/04/06 07:37:27 AM] Writing properties/obj_type_1/orientation (194762,)\n",
      "[INFO][2023/04/06 07:37:27 AM] Writing properties/obj_type_1/mean_intensity (194762,)\n",
      "[INFO][2023/04/06 07:37:27 AM] Writing properties/obj_type_1/class_id (194762,)\n",
      "[INFO][2023/04/06 07:37:28 AM] Writing tracks/obj_type_1\n",
      "[INFO][2023/04/06 07:37:28 AM] Writing dummies/obj_type_1\n",
      "[INFO][2023/04/06 07:37:28 AM] Writing LBEP/obj_type_1\n",
      "[INFO][2023/04/06 07:37:28 AM] Writing fates/obj_type_1\n",
      "[INFO][2023/04/06 07:37:28 AM] Closing HDF file: /home/groups/heiserlab_genomics/home/dane/CellTracking/images/HC01701/Analysis/CntB/intermediate_files/tracking/B2/field_1/results/tracking.h5\n",
      "[INFO][2023/04/06 07:37:55 AM] Ending BayesianTracker session\n",
      "[INFO][2023/04/06 07:38:06 AM] Localizing objects from segmentation...\n",
      "[INFO][2023/04/06 07:38:06 AM] Found intensity_image data\n",
      "[INFO][2023/04/06 07:38:06 AM] Calculating weighted centroids using intensity_image\n",
      "[INFO][2023/04/06 07:39:12 AM] Objects are of type: <class 'dict'>\n",
      "[INFO][2023/04/06 07:39:14 AM] ...Found 194365 objects in 381 frames.\n",
      "[INFO][2023/04/06 07:39:14 AM] Loaded btrack: /home/exacloud/gscratch/HeiserLab/software/BayesianTracker/btrack/libs/libtracker.so\n",
      "[INFO][2023/04/06 07:39:14 AM] btrack (v0.5.0) library imported\n",
      "[INFO][2023/04/06 07:39:14 AM] Starting BayesianTracker session\n",
      "[INFO][2023/04/06 07:39:14 AM] Loading configuration file: ../models/cell_config_HCC1143.json\n",
      "[INFO][2023/04/06 07:39:14 AM] Objects are of type: <class 'list'>\n",
      "[INFO][2023/04/06 07:39:18 AM] Starting tracking... \n",
      "[INFO][2023/04/06 07:39:18 AM] Update using: ['VISUAL', 'MOTION']\n",
      "[INFO][2023/04/06 07:39:18 AM] Tracking objects in frames 0 to 99 (of 381)...\n",
      "[INFO][2023/04/06 07:39:24 AM]  - Timing (Bayesian updates: 30.00ms, Linking: 0.00ms)\n",
      "[INFO][2023/04/06 07:39:24 AM]  - Probabilities (Link: 0.99999, Lost: 1.00000)\n",
      "[INFO][2023/04/06 07:39:24 AM]  - Stats (Active: 356, Lost: 1224, Conflicts resolved: 1836)\n",
      "[INFO][2023/04/06 07:39:24 AM] Tracking objects in frames 100 to 199 (of 381)...\n",
      "[INFO][2023/04/06 07:39:44 AM]  - Timing (Bayesian updates: 90.00ms, Linking: 0.00ms)\n",
      "[INFO][2023/04/06 07:39:44 AM]  - Probabilities (Link: 1.00000, Lost: 0.99812)\n",
      "[INFO][2023/04/06 07:39:44 AM]  - Stats (Active: 583, Lost: 2491, Conflicts resolved: 3871)\n",
      "[INFO][2023/04/06 07:39:44 AM] Tracking objects in frames 200 to 299 (of 381)...\n",
      "[INFO][2023/04/06 07:40:28 AM]  - Timing (Bayesian updates: 180.00ms, Linking: 10.00ms)\n",
      "[INFO][2023/04/06 07:40:28 AM]  - Probabilities (Link: 1.00000, Lost: 1.00000)\n",
      "[INFO][2023/04/06 07:40:28 AM]  - Stats (Active: 743, Lost: 4563, Conflicts resolved: 7640)\n",
      "[INFO][2023/04/06 07:40:28 AM] Tracking objects in frames 300 to 381 (of 381)...\n",
      "[INFO][2023/04/06 07:41:15 AM]  - Timing (Bayesian updates: 230.00ms, Linking: 0.00ms)\n",
      "[INFO][2023/04/06 07:41:15 AM]  - Probabilities (Link: 1.00000, Lost: 1.00000)\n",
      "[INFO][2023/04/06 07:41:15 AM] SUCCESS.\n",
      "[INFO][2023/04/06 07:41:15 AM]  - Found 11211 tracks in 381 frames (in 0.0s)\n",
      "[INFO][2023/04/06 07:41:15 AM]  - Inserted 2484 dummy objects to fill tracking gaps\n",
      "[WARNING][2023/04/06 07:41:15 AM] `track_interactive` will be deprecated. Use `track` instead.\n",
      "[INFO][2023/04/06 07:41:15 AM] Starting tracking... \n",
      "[INFO][2023/04/06 07:41:15 AM] Update using: ['VISUAL', 'MOTION']\n",
      "[INFO][2023/04/06 07:41:15 AM] SUCCESS.\n",
      "[INFO][2023/04/06 07:41:15 AM]  - Found 11211 tracks in 381 frames (in 0.0s)\n",
      "[INFO][2023/04/06 07:41:15 AM]  - Inserted 2484 dummy objects to fill tracking gaps\n",
      "[INFO][2023/04/06 07:41:15 AM] Loading hypothesis model: cell_hypothesis\n",
      "[INFO][2023/04/06 07:41:15 AM] Calculating hypotheses (relax: True)...\n",
      "[INFO][2023/04/06 07:41:17 AM] Setting up constraints matrix for global optimisation...\n",
      "[INFO][2023/04/06 07:41:17 AM] Using GLPK options: {'tm_lim': 600000}...\n",
      "[INFO][2023/04/06 07:41:19 AM] Optimizing...\n",
      "[INFO][2023/04/06 07:41:54 AM] Optimization complete. (Solution: optimal)\n",
      "[INFO][2023/04/06 07:41:54 AM]  - Fates.FALSE_POSITIVE: 368 (of 11211)\n",
      "[INFO][2023/04/06 07:41:54 AM]  - Fates.LINK: 5914 (of 14447)\n",
      "[INFO][2023/04/06 07:41:55 AM]  - Fates.DIVIDE: 1170 (of 9990)\n",
      "[INFO][2023/04/06 07:41:55 AM]  - Fates.INITIALIZE_BORDER: 402 (of 924)\n",
      "[INFO][2023/04/06 07:41:55 AM]  - Fates.INITIALIZE_FRONT: 225 (of 264)\n",
      "[INFO][2023/04/06 07:41:55 AM]  - Fates.INITIALIZE_LAZY: 1962 (of 10023)\n",
      "[INFO][2023/04/06 07:41:55 AM]  - Fates.TERMINATE_BORDER: 436 (of 879)\n",
      "[INFO][2023/04/06 07:41:55 AM]  - Fates.TERMINATE_BACK: 864 (of 978)\n",
      "[INFO][2023/04/06 07:41:55 AM]  - Fates.TERMINATE_LAZY: 2459 (of 9354)\n",
      "[INFO][2023/04/06 07:41:55 AM]  - TOTAL: 58070 hypotheses\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLPK Integer Optimizer, v4.65\n",
      "44844 rows, 58070 columns, 103708 non-zeros\n",
      "58070 integer variables, all of which are binary\n",
      "Preprocessing...\n",
      "22422 rows, 58070 columns, 103708 non-zeros\n",
      "58070 integer variables, all of which are binary\n",
      "Scaling...\n",
      " A: min|aij| =  1.000e+00  max|aij| =  1.000e+00  ratio =  1.000e+00\n",
      "Problem data seem to be well scaled\n",
      "Constructing initial basis...\n",
      "Size of triangular part is 22422\n",
      "Solving LP relaxation...\n",
      "GLPK Simplex Optimizer, v4.65\n",
      "22422 rows, 58070 columns, 103708 non-zeros\n",
      "*     0: obj =   1.364194302e+05 inf =   0.000e+00 (26046)\n",
      "Perturbing LP to avoid stalling [454]...\n",
      "*  3360: obj =   1.032476135e+05 inf =   0.000e+00 (17886) 1\n",
      "*  6232: obj =   8.347379061e+04 inf =   0.000e+00 (13080) 7\n",
      "*  9474: obj =   6.067125489e+04 inf =   0.000e+00 (10176) 3\n",
      "* 12412: obj =   4.768546768e+04 inf =   1.000e-09 (7840) 5\n",
      "* 15417: obj =   3.984390600e+04 inf =   1.000e-09 (4850) 7\n",
      "* 18119: obj =   3.601569766e+04 inf =   1.400e-08 (2075) 15\n",
      "Removing LP perturbation [19807]...\n",
      "* 19807: obj =   3.567909724e+04 inf =   0.000e+00 (0) 8\n",
      "OPTIMAL LP SOLUTION FOUND\n",
      "Integer optimization begins...\n",
      "Long-step dual simplex will be used\n",
      "+ 19807: mip =     not found yet >=              -inf        (1; 0)\n",
      "+ 19828: >>>>>   3.568596435e+04 >=   3.567930831e+04 < 0.1% (13; 0)\n",
      "+ 19848: >>>>>   3.567930973e+04 >=   3.567930973e+04 < 0.1% (18; 2)\n",
      "+ 19848: mip =   3.567930973e+04 >=     tree is empty   0.0% (0; 39)\n",
      "INTEGER OPTIMAL SOLUTION FOUND\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2023/04/06 07:41:55 AM] Completed optimization with 5297 tracks\n",
      "[INFO][2023/04/06 07:41:55 AM] Opening HDF file: /home/groups/heiserlab_genomics/home/dane/CellTracking/images/HC01701/Analysis/CntB/intermediate_files/tracking/B2/field_2/results/tracking.h5...\n",
      "[INFO][2023/04/06 07:41:57 AM] Writing objects/obj_type_1\n",
      "[INFO][2023/04/06 07:41:57 AM] Writing labels/obj_type_1\n",
      "[INFO][2023/04/06 07:41:57 AM] Loading objects/obj_type_1 (194365, 5) (194365 filtered: None)\n",
      "[INFO][2023/04/06 07:41:58 AM] Writing properties/obj_type_1/area (194365,)\n",
      "[INFO][2023/04/06 07:41:58 AM] Writing properties/obj_type_1/major_axis_length (194365,)\n",
      "[INFO][2023/04/06 07:41:58 AM] Writing properties/obj_type_1/minor_axis_length (194365,)\n",
      "[INFO][2023/04/06 07:41:58 AM] Writing properties/obj_type_1/orientation (194365,)\n",
      "[INFO][2023/04/06 07:41:58 AM] Writing properties/obj_type_1/mean_intensity (194365,)\n",
      "[INFO][2023/04/06 07:41:58 AM] Writing properties/obj_type_1/class_id (194365,)\n",
      "[INFO][2023/04/06 07:41:59 AM] Writing tracks/obj_type_1\n",
      "[INFO][2023/04/06 07:41:59 AM] Writing dummies/obj_type_1\n",
      "[INFO][2023/04/06 07:41:59 AM] Writing LBEP/obj_type_1\n",
      "[INFO][2023/04/06 07:41:59 AM] Writing fates/obj_type_1\n",
      "[INFO][2023/04/06 07:41:59 AM] Closing HDF file: /home/groups/heiserlab_genomics/home/dane/CellTracking/images/HC01701/Analysis/CntB/intermediate_files/tracking/B2/field_2/results/tracking.h5\n",
      "[INFO][2023/04/06 07:42:38 AM] Ending BayesianTracker session\n",
      "[INFO][2023/04/06 07:42:52 AM] Localizing objects from segmentation...\n",
      "[INFO][2023/04/06 07:42:52 AM] Found intensity_image data\n",
      "[INFO][2023/04/06 07:42:52 AM] Calculating weighted centroids using intensity_image\n",
      "[INFO][2023/04/06 07:43:41 AM] Objects are of type: <class 'dict'>\n",
      "[INFO][2023/04/06 07:43:42 AM] ...Found 127692 objects in 381 frames.\n",
      "[INFO][2023/04/06 07:43:42 AM] Loaded btrack: /home/exacloud/gscratch/HeiserLab/software/BayesianTracker/btrack/libs/libtracker.so\n",
      "[INFO][2023/04/06 07:43:42 AM] btrack (v0.5.0) library imported\n",
      "[INFO][2023/04/06 07:43:42 AM] Starting BayesianTracker session\n",
      "[INFO][2023/04/06 07:43:42 AM] Loading configuration file: ../models/cell_config_HCC1143.json\n",
      "[INFO][2023/04/06 07:43:42 AM] Objects are of type: <class 'list'>\n",
      "[INFO][2023/04/06 07:43:45 AM] Starting tracking... \n",
      "[INFO][2023/04/06 07:43:45 AM] Update using: ['VISUAL', 'MOTION']\n",
      "[INFO][2023/04/06 07:43:45 AM] Tracking objects in frames 0 to 99 (of 381)...\n",
      "[INFO][2023/04/06 07:43:47 AM]  - Timing (Bayesian updates: 0.00ms, Linking: 0.00ms)\n",
      "[INFO][2023/04/06 07:43:47 AM]  - Probabilities (Link: 1.00000, Lost: 0.56008)\n",
      "[INFO][2023/04/06 07:43:47 AM]  - Stats (Active: 227, Lost: 751, Conflicts resolved: 1023)\n",
      "[INFO][2023/04/06 07:43:47 AM] Tracking objects in frames 100 to 199 (of 381)...\n",
      "[INFO][2023/04/06 07:43:54 AM]  - Timing (Bayesian updates: 20.00ms, Linking: 0.00ms)\n",
      "[INFO][2023/04/06 07:43:54 AM]  - Probabilities (Link: 1.00000, Lost: 1.00000)\n",
      "[INFO][2023/04/06 07:43:54 AM]  - Stats (Active: 366, Lost: 1465, Conflicts resolved: 2034)\n",
      "[INFO][2023/04/06 07:43:54 AM] Tracking objects in frames 200 to 299 (of 381)...\n",
      "[INFO][2023/04/06 07:44:09 AM]  - Timing (Bayesian updates: 60.00ms, Linking: 0.00ms)\n",
      "[INFO][2023/04/06 07:44:09 AM]  - Probabilities (Link: 1.00000, Lost: 0.99028)\n",
      "[INFO][2023/04/06 07:44:09 AM]  - Stats (Active: 480, Lost: 2400, Conflicts resolved: 3878)\n",
      "[INFO][2023/04/06 07:44:09 AM] Tracking objects in frames 300 to 381 (of 381)...\n",
      "[INFO][2023/04/06 07:44:27 AM]  - Timing (Bayesian updates: 80.00ms, Linking: 0.00ms)\n",
      "[INFO][2023/04/06 07:44:27 AM]  - Probabilities (Link: 1.00000, Lost: 1.00000)\n",
      "[INFO][2023/04/06 07:44:27 AM] SUCCESS.\n",
      "[INFO][2023/04/06 07:44:27 AM]  - Found 5835 tracks in 381 frames (in 0.0s)\n",
      "[INFO][2023/04/06 07:44:27 AM]  - Inserted 1198 dummy objects to fill tracking gaps\n",
      "[WARNING][2023/04/06 07:44:27 AM] `track_interactive` will be deprecated. Use `track` instead.\n",
      "[INFO][2023/04/06 07:44:27 AM] Starting tracking... \n",
      "[INFO][2023/04/06 07:44:27 AM] Update using: ['VISUAL', 'MOTION']\n",
      "[INFO][2023/04/06 07:44:27 AM] SUCCESS.\n",
      "[INFO][2023/04/06 07:44:27 AM]  - Found 5835 tracks in 381 frames (in 0.0s)\n",
      "[INFO][2023/04/06 07:44:27 AM]  - Inserted 1198 dummy objects to fill tracking gaps\n",
      "[INFO][2023/04/06 07:44:27 AM] Loading hypothesis model: cell_hypothesis\n",
      "[INFO][2023/04/06 07:44:27 AM] Calculating hypotheses (relax: True)...\n",
      "[INFO][2023/04/06 07:44:27 AM] Setting up constraints matrix for global optimisation...\n",
      "[INFO][2023/04/06 07:44:27 AM] Using GLPK options: {'tm_lim': 600000}...\n",
      "[INFO][2023/04/06 07:44:27 AM] Optimizing...\n",
      "[INFO][2023/04/06 07:44:34 AM] Optimization complete. (Solution: optimal)\n",
      "[INFO][2023/04/06 07:44:34 AM]  - Fates.FALSE_POSITIVE: 249 (of 5835)\n",
      "[INFO][2023/04/06 07:44:34 AM]  - Fates.LINK: 2720 (of 5993)\n",
      "[INFO][2023/04/06 07:44:34 AM]  - Fates.DIVIDE: 567 (of 3323)\n",
      "[INFO][2023/04/06 07:44:34 AM]  - Fates.INITIALIZE_BORDER: 304 (of 612)\n",
      "[INFO][2023/04/06 07:44:34 AM]  - Fates.INITIALIZE_FRONT: 167 (of 184)\n",
      "[INFO][2023/04/06 07:44:34 AM]  - Fates.INITIALIZE_LAZY: 1261 (of 5039)\n",
      "[INFO][2023/04/06 07:44:34 AM]  - Fates.TERMINATE_BORDER: 330 (of 592)\n",
      "[INFO][2023/04/06 07:44:34 AM]  - Fates.TERMINATE_BACK: 589 (of 652)\n",
      "[INFO][2023/04/06 07:44:34 AM]  - Fates.TERMINATE_LAZY: 1380 (of 4591)\n",
      "[INFO][2023/04/06 07:44:34 AM]  - TOTAL: 26821 hypotheses\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLPK Integer Optimizer, v4.65\n",
      "23340 rows, 26821 columns, 45295 non-zeros\n",
      "26821 integer variables, all of which are binary\n",
      "Preprocessing...\n",
      "11670 rows, 26821 columns, 45295 non-zeros\n",
      "26821 integer variables, all of which are binary\n",
      "Scaling...\n",
      " A: min|aij| =  1.000e+00  max|aij| =  1.000e+00  ratio =  1.000e+00\n",
      "Problem data seem to be well scaled\n",
      "Constructing initial basis...\n",
      "Size of triangular part is 11670\n",
      "Solving LP relaxation...\n",
      "GLPK Simplex Optimizer, v4.65\n",
      "11670 rows, 26821 columns, 45295 non-zeros\n",
      "*     0: obj =   6.841496851e+04 inf =   0.000e+00 (10005)\n",
      "Perturbing LP to avoid stalling [520]...\n",
      "*  6864: obj =   2.245713920e+04 inf =   7.000e-09 (1136) 8\n",
      "Removing LP perturbation [7908]...\n",
      "*  7908: obj =   2.163594465e+04 inf =   0.000e+00 (0) 5\n",
      "OPTIMAL LP SOLUTION FOUND\n",
      "Integer optimization begins...\n",
      "Long-step dual simplex will be used\n",
      "+  7908: mip =     not found yet >=              -inf        (1; 0)\n",
      "+  7914: >>>>>   2.163598379e+04 >=   2.163598379e+04   0.0% (4; 0)\n",
      "+  7914: mip =   2.163598379e+04 >=     tree is empty   0.0% (0; 7)\n",
      "INTEGER OPTIMAL SOLUTION FOUND\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2023/04/06 07:44:34 AM] Completed optimization with 3115 tracks\n",
      "[INFO][2023/04/06 07:44:34 AM] Opening HDF file: /home/groups/heiserlab_genomics/home/dane/CellTracking/images/HC01701/Analysis/CntB/intermediate_files/tracking/B2/field_3/results/tracking.h5...\n",
      "[INFO][2023/04/06 07:44:35 AM] Writing objects/obj_type_1\n",
      "[INFO][2023/04/06 07:44:35 AM] Writing labels/obj_type_1\n",
      "[INFO][2023/04/06 07:44:35 AM] Loading objects/obj_type_1 (127692, 5) (127692 filtered: None)\n",
      "[INFO][2023/04/06 07:44:36 AM] Writing properties/obj_type_1/area (127692,)\n",
      "[INFO][2023/04/06 07:44:36 AM] Writing properties/obj_type_1/major_axis_length (127692,)\n",
      "[INFO][2023/04/06 07:44:36 AM] Writing properties/obj_type_1/minor_axis_length (127692,)\n",
      "[INFO][2023/04/06 07:44:36 AM] Writing properties/obj_type_1/orientation (127692,)\n",
      "[INFO][2023/04/06 07:44:36 AM] Writing properties/obj_type_1/mean_intensity (127692,)\n",
      "[INFO][2023/04/06 07:44:36 AM] Writing properties/obj_type_1/class_id (127692,)\n",
      "[INFO][2023/04/06 07:44:36 AM] Writing tracks/obj_type_1\n",
      "[INFO][2023/04/06 07:44:36 AM] Writing dummies/obj_type_1\n",
      "[INFO][2023/04/06 07:44:36 AM] Writing LBEP/obj_type_1\n",
      "[INFO][2023/04/06 07:44:36 AM] Writing fates/obj_type_1\n",
      "[INFO][2023/04/06 07:44:36 AM] Closing HDF file: /home/groups/heiserlab_genomics/home/dane/CellTracking/images/HC01701/Analysis/CntB/intermediate_files/tracking/B2/field_3/results/tracking.h5\n",
      "[INFO][2023/04/06 07:45:17 AM] Ending BayesianTracker session\n",
      "[INFO][2023/04/06 07:45:27 AM] Localizing objects from segmentation...\n",
      "[INFO][2023/04/06 07:45:27 AM] Found intensity_image data\n",
      "[INFO][2023/04/06 07:45:27 AM] Calculating weighted centroids using intensity_image\n",
      "[INFO][2023/04/06 07:46:28 AM] Objects are of type: <class 'dict'>\n",
      "[INFO][2023/04/06 07:46:29 AM] ...Found 166605 objects in 381 frames.\n",
      "[INFO][2023/04/06 07:46:29 AM] Loaded btrack: /home/exacloud/gscratch/HeiserLab/software/BayesianTracker/btrack/libs/libtracker.so\n",
      "[INFO][2023/04/06 07:46:29 AM] btrack (v0.5.0) library imported\n",
      "[INFO][2023/04/06 07:46:29 AM] Starting BayesianTracker session\n",
      "[INFO][2023/04/06 07:46:29 AM] Loading configuration file: ../models/cell_config_HCC1143.json\n",
      "[INFO][2023/04/06 07:46:29 AM] Objects are of type: <class 'list'>\n",
      "[INFO][2023/04/06 07:46:33 AM] Starting tracking... \n",
      "[INFO][2023/04/06 07:46:33 AM] Update using: ['VISUAL', 'MOTION']\n",
      "[INFO][2023/04/06 07:46:33 AM] Tracking objects in frames 0 to 99 (of 381)...\n",
      "[INFO][2023/04/06 07:46:37 AM]  - Timing (Bayesian updates: 20.00ms, Linking: 0.00ms)\n",
      "[INFO][2023/04/06 07:46:37 AM]  - Probabilities (Link: 1.00000, Lost: 1.00000)\n",
      "[INFO][2023/04/06 07:46:37 AM]  - Stats (Active: 298, Lost: 982, Conflicts resolved: 1200)\n",
      "[INFO][2023/04/06 07:46:37 AM] Tracking objects in frames 100 to 199 (of 381)...\n",
      "[INFO][2023/04/06 07:46:50 AM]  - Timing (Bayesian updates: 60.00ms, Linking: 10.00ms)\n",
      "[INFO][2023/04/06 07:46:50 AM]  - Probabilities (Link: 1.00000, Lost: 1.00000)\n",
      "[INFO][2023/04/06 07:46:50 AM]  - Stats (Active: 500, Lost: 1980, Conflicts resolved: 2692)\n",
      "[INFO][2023/04/06 07:46:50 AM] Tracking objects in frames 200 to 299 (of 381)...\n",
      "[INFO][2023/04/06 07:47:19 AM]  - Timing (Bayesian updates: 100.00ms, Linking: 10.00ms)\n",
      "[INFO][2023/04/06 07:47:19 AM]  - Probabilities (Link: 1.00000, Lost: 0.99994)\n",
      "[INFO][2023/04/06 07:47:19 AM]  - Stats (Active: 618, Lost: 3346, Conflicts resolved: 5144)\n",
      "[INFO][2023/04/06 07:47:19 AM] Tracking objects in frames 300 to 381 (of 381)...\n",
      "[INFO][2023/04/06 07:47:52 AM]  - Timing (Bayesian updates: 140.00ms, Linking: 10.00ms)\n",
      "[INFO][2023/04/06 07:47:52 AM]  - Probabilities (Link: 1.00000, Lost: 0.50390)\n",
      "[INFO][2023/04/06 07:47:52 AM] SUCCESS.\n",
      "[INFO][2023/04/06 07:47:52 AM]  - Found 7995 tracks in 381 frames (in 0.0s)\n",
      "[INFO][2023/04/06 07:47:52 AM]  - Inserted 1700 dummy objects to fill tracking gaps\n",
      "[WARNING][2023/04/06 07:47:52 AM] `track_interactive` will be deprecated. Use `track` instead.\n",
      "[INFO][2023/04/06 07:47:52 AM] Starting tracking... \n",
      "[INFO][2023/04/06 07:47:52 AM] Update using: ['VISUAL', 'MOTION']\n",
      "[INFO][2023/04/06 07:47:52 AM] SUCCESS.\n",
      "[INFO][2023/04/06 07:47:52 AM]  - Found 7995 tracks in 381 frames (in 0.0s)\n",
      "[INFO][2023/04/06 07:47:52 AM]  - Inserted 1700 dummy objects to fill tracking gaps\n",
      "[INFO][2023/04/06 07:47:52 AM] Loading hypothesis model: cell_hypothesis\n",
      "[INFO][2023/04/06 07:47:52 AM] Calculating hypotheses (relax: True)...\n",
      "[INFO][2023/04/06 07:47:53 AM] Setting up constraints matrix for global optimisation...\n",
      "[INFO][2023/04/06 07:47:53 AM] Using GLPK options: {'tm_lim': 600000}...\n",
      "[INFO][2023/04/06 07:47:53 AM] Optimizing...\n",
      "[INFO][2023/04/06 07:48:05 AM] Optimization complete. (Solution: optimal)\n",
      "[INFO][2023/04/06 07:48:05 AM]  - Fates.FALSE_POSITIVE: 305 (of 7995)\n",
      "[INFO][2023/04/06 07:48:05 AM]  - Fates.LINK: 3982 (of 8551)\n",
      "[INFO][2023/04/06 07:48:05 AM]  - Fates.DIVIDE: 732 (of 4770)\n",
      "[INFO][2023/04/06 07:48:05 AM]  - Fates.INITIALIZE_BORDER: 383 (of 890)\n",
      "[INFO][2023/04/06 07:48:05 AM]  - Fates.INITIALIZE_FRONT: 203 (of 232)\n",
      "[INFO][2023/04/06 07:48:05 AM]  - Fates.INITIALIZE_LAZY: 1658 (of 6873)\n",
      "[INFO][2023/04/06 07:48:05 AM]  - Fates.TERMINATE_BORDER: 421 (of 841)\n",
      "[INFO][2023/04/06 07:48:05 AM]  - Fates.TERMINATE_BACK: 734 (of 806)\n",
      "[INFO][2023/04/06 07:48:05 AM]  - Fates.TERMINATE_LAZY: 1821 (of 6348)\n",
      "[INFO][2023/04/06 07:48:05 AM]  - TOTAL: 37306 hypotheses\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLPK Integer Optimizer, v4.65\n",
      "31980 rows, 37306 columns, 63392 non-zeros\n",
      "37306 integer variables, all of which are binary\n",
      "Preprocessing...\n",
      "15990 rows, 37306 columns, 63392 non-zeros\n",
      "37306 integer variables, all of which are binary\n",
      "Scaling...\n",
      " A: min|aij| =  1.000e+00  max|aij| =  1.000e+00  ratio =  1.000e+00\n",
      "Problem data seem to be well scaled\n",
      "Constructing initial basis...\n",
      "Size of triangular part is 15990\n",
      "Solving LP relaxation...\n",
      "GLPK Simplex Optimizer, v4.65\n",
      "15990 rows, 37306 columns, 63392 non-zeros\n",
      "*     0: obj =   9.482094087e+04 inf =   0.000e+00 (14322)\n",
      "Perturbing LP to avoid stalling [512]...\n",
      "*  5073: obj =   4.955454502e+04 inf =   0.000e+00 (6036) 4\n",
      "*  9864: obj =   2.961003385e+04 inf =   1.110e-16 (1636) 8\n",
      "Removing LP perturbation [11348]...\n",
      "* 11348: obj =   2.847648203e+04 inf =   0.000e+00 (0) 8\n",
      "OPTIMAL LP SOLUTION FOUND\n",
      "Integer optimization begins...\n",
      "Long-step dual simplex will be used\n",
      "+ 11348: mip =     not found yet >=              -inf        (1; 0)\n",
      "+ 11353: >>>>>   2.847653974e+04 >=   2.847653974e+04   0.0% (4; 0)\n",
      "+ 11353: mip =   2.847653974e+04 >=     tree is empty   0.0% (0; 7)\n",
      "INTEGER OPTIMAL SOLUTION FOUND\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2023/04/06 07:48:06 AM] Completed optimization with 4013 tracks\n",
      "[INFO][2023/04/06 07:48:06 AM] Opening HDF file: /home/groups/heiserlab_genomics/home/dane/CellTracking/images/HC01701/Analysis/CntB/intermediate_files/tracking/B2/field_4/results/tracking.h5...\n",
      "[INFO][2023/04/06 07:48:07 AM] Writing objects/obj_type_1\n",
      "[INFO][2023/04/06 07:48:07 AM] Writing labels/obj_type_1\n",
      "[INFO][2023/04/06 07:48:07 AM] Loading objects/obj_type_1 (166605, 5) (166605 filtered: None)\n",
      "[INFO][2023/04/06 07:48:09 AM] Writing properties/obj_type_1/area (166605,)\n",
      "[INFO][2023/04/06 07:48:09 AM] Writing properties/obj_type_1/major_axis_length (166605,)\n",
      "[INFO][2023/04/06 07:48:09 AM] Writing properties/obj_type_1/minor_axis_length (166605,)\n",
      "[INFO][2023/04/06 07:48:09 AM] Writing properties/obj_type_1/orientation (166605,)\n",
      "[INFO][2023/04/06 07:48:09 AM] Writing properties/obj_type_1/mean_intensity (166605,)\n",
      "[INFO][2023/04/06 07:48:10 AM] Writing properties/obj_type_1/class_id (166605,)\n",
      "[INFO][2023/04/06 07:48:10 AM] Writing tracks/obj_type_1\n",
      "[INFO][2023/04/06 07:48:10 AM] Writing dummies/obj_type_1\n",
      "[INFO][2023/04/06 07:48:10 AM] Writing LBEP/obj_type_1\n",
      "[INFO][2023/04/06 07:48:10 AM] Writing fates/obj_type_1\n",
      "[INFO][2023/04/06 07:48:10 AM] Closing HDF file: /home/groups/heiserlab_genomics/home/dane/CellTracking/images/HC01701/Analysis/CntB/intermediate_files/tracking/B2/field_4/results/tracking.h5\n",
      "[INFO][2023/04/06 07:48:51 AM] Ending BayesianTracker session\n"
     ]
    }
   ],
   "source": [
    "#first_frame = 0\n",
    "#last_frame = 193\n",
    "\n",
    "# features to be calculated from image data\n",
    "FEATURES = [\"area\", \"major_axis_length\", \"minor_axis_length\", \"orientation\",\"mean_intensity\"]\n",
    "\n",
    "TRACKING_UPDATES = [\n",
    "  \"motion\",\n",
    "  \"visual\",\n",
    "]\n",
    "\n",
    "def segmentation_arr(files):\n",
    "    \"\"\"Segmentation as numpy array.\"\"\"\n",
    "    \n",
    "    stack = []\n",
    "    for filename in files:\n",
    "        img = io.imread(filename)\n",
    "        stack.append(img)\n",
    "    return np.stack(stack, axis=0)\n",
    "\n",
    "for subdir in subdirectories:\n",
    "    field = re.findall(\"field_[1-9]\",subdir)[0]\n",
    "    field_num = re.findall(\"[0-9]\", field)[0]\n",
    "    \n",
    "    #only run if results file is not present\n",
    "    results_file_name = os.path.join(tracking_path,well,field,\"results\",'tracking.h5')\n",
    "    if not os.path.exists(results_file_name):\n",
    "        cell_mask_file_names = sorted(glob.glob(os.path.join(tracking_path, well,field, 'cell_masks','mask*.tif')))\n",
    "        #cell_mask_file_names = sorted(cell_mask_file_names)[first_frame:last_frame] #DEBUG do not clip the number of images\n",
    "\n",
    "        #use the green cell cycle reporter images for intensity values\n",
    "        cell_cycle_stack_filename = os.path.join(registered_stacks_path, plateID+\"_G_\"+well+\"_\"+field_num+\"_reg_stack.tif\")\n",
    "        cell_cycle_stack = io.imread(cell_cycle_stack_filename)\n",
    "        #cell_cycle_stack = io.imread(cell_cycle_stack_filename)[first_frame:last_frame,:,:] #trim stack if needed\n",
    "        cell_mask_stack = segmentation_arr(cell_mask_file_names)\n",
    "\n",
    "        btrack_obj = btrack.utils.segmentation_to_objects(\n",
    "        cell_mask_stack, \n",
    "        intensity_image = cell_cycle_stack,\n",
    "        properties=tuple(FEATURES),\n",
    "        assign_class_ID = True\n",
    "        )\n",
    "\n",
    "        # initialise a tracker session using a context manager\n",
    "        with btrack.BayesianTracker() as tracker:\n",
    "\n",
    "            # configure the tracker using a config file\n",
    "            tracker.configure_from_file('../models/cell_config_HCC1143.json') \n",
    "            tracker.max_search_radius = 50\n",
    "            # set up the features to use as a list\n",
    "            tracker.features = FEATURES\n",
    "\n",
    "            # append the objects to be tracked\n",
    "            tracker.append(btrack_obj)\n",
    "            # tell the tracker to use certain information while performing tracking\n",
    "            tracker.track(tracking_updates=TRACKING_UPDATES)\n",
    "\n",
    "            # set the volume\n",
    "            tracker.volume=((0, cell_cycle_stack.shape[2]), (0, cell_cycle_stack.shape[1]), (-1e5, 1e5))\n",
    "\n",
    "            # track them (in interactive mode)\n",
    "            tracker.track_interactive(step_size=200)\n",
    "\n",
    "            # generate hypotheses and run the global optimizer\n",
    "            tracker.optimize(options={\"tm_lim\": 60_000 * 10})\n",
    "            #save the tracker results in an H5 file\n",
    "            tracker.export(results_file_name, obj_type='obj_type_1')\n",
    "            ####issue work around reload track data from file\n",
    "            #HDF5 object has objects and tracks groups\n",
    "            #these are all stored as values\n",
    "            #tracker.tracks is a OrderedDict of dataframes\n",
    "            #The values stored in the HDF5 object have been filtered\n",
    "            #tracking = h5py.File(results_file_name, 'r')\n",
    "            #tracksH5 = tracking['tracks']['obj_type_1']['tracks']\n",
    "                        \n",
    "            #generate cell tracking challenge compatible mask files\n",
    "            tracks = tracker.tracks\n",
    "            ctc = btrack.utils.update_segmentation(cell_mask_stack, tracks)\n",
    "            #Use skimage to save individual mask images with tracked label\n",
    "            for i in range(len(ctc)):\n",
    "                io.imsave(tracking_path+well+\"/\"+field+\"/results/\"+\"mask%03.d.tif\"%i, ctc[i].astype(np.int16), plugin='tifffile', check_contrast=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ae823b-83ff-4883-a0ec-cb5b5c20bfd2",
   "metadata": {},
   "source": [
    "#### Identify cells\n",
    "Read in the tracking results  \n",
    "res_track.txt - A text file representing an acyclic graph for the whole image sequence. Every line corresponds to a single track that is encoded by four numbers separated by a space:  \n",
    "L B E P where  \n",
    "L - a unique label of the track (label of markers, 16-bit positive value)  \n",
    "B - a zero-based temporal index of the frame in which the track begins  \n",
    "E - a zero-based temporal index of the frame in which the track ends  \n",
    "P - label of the parent track (0 is used when no parent is defined)\n",
    "\n",
    "\n",
    "Filter the track objects keeping the parents and those with a minimum track length and save the results to tracks.csv    \n",
    "\n",
    "Create a new file tracks.csv with the following columns:  \n",
    "label - a unique label of the track (label of markers, 16-bit positive value)  \n",
    "begins - a zero-based temporal index of the frame in which the track begins  \n",
    "ends - a zero-based temporal index of the frame in which the track ends  \n",
    "parent - label of the parent track (0 is used when no parent is defined)  \n",
    "length - The number of frames that the cell is identified in  \n",
    "plateID - Character string of the plate's ID such as AU02001  \n",
    "well - Character string of the well such as A1  \n",
    "field - Integer of the image field within the well  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfb5dee-244c-4564-91fe-240a0c8e4b4d",
   "metadata": {},
   "source": [
    "tracking_filename = os.path.join(tracking_path,well,field,\"results\",\"tracking.h5\")\n",
    "res_flt_filename = tracking_filename.replace(\"tracking.h5\",\"tracks.csv\")\n",
    "tracking = h5py.File(tracking_filename, 'r')\n",
    "tracking_tracks = tracking['tracks']\n",
    "\n",
    "lbepr = tracking_tracks['obj_type_1']['LBEPR'][:]\n",
    "lbepr_df = pd.DataFrame(lbepr, columns=['label','begins','ends','parent','root','depth'])\n",
    "lbepr_df['length'] = lbepr_df.ends - lbepr_df.begins + 1\n",
    "#check if object is a parent\n",
    "progeny = lbepr_df[lbepr_df['label']!=lbepr_df['parent']]\n",
    "lbepr_df[\"is_parent\"] = lbepr_df['label'].isin(progeny['parent'])\n",
    "lbepr_df['plateID'] = plateID\n",
    "lbepr_df['well'] = well\n",
    "lbepr_df['field'] = field.replace(\"field_\",\"\")\n",
    "tracking.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32d28e8b-4407-4f7f-afa0-7cf77009acfb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#set filter parameters\n",
    "min_track_length = 1 #do no filtering\n",
    "#loop through the results from each segmented field\n",
    "for subdir in subdirectories:\n",
    "    field = re.findall(\"field_[1-9]\",subdir)[0]\n",
    "    tracking_filename = os.path.join(tracking_path,well,field,\"results\",\"tracking.h5\")\n",
    "    res_flt_filename = tracking_filename.replace(\"tracking.h5\",\"tracks.csv\")\n",
    "    tracking = h5py.File(tracking_filename, 'r')\n",
    "    tracking_tracks = tracking['tracks']\n",
    "\n",
    "    lbepr = tracking_tracks['obj_type_1']['LBEPR'][:]\n",
    "    lbepr_df = pd.DataFrame(lbepr, columns=['label','begins','ends','parent','root','depth'])\n",
    "    lbepr_df['length'] = lbepr_df.ends - lbepr_df.begins + 1\n",
    "    #check if object is a parent\n",
    "    progeny = lbepr_df[lbepr_df['label']!=lbepr_df['parent']]\n",
    "    lbepr_df[\"is_parent\"] = lbepr_df['label'].isin(progeny['parent'])\n",
    "    lbepr_df['plateID'] = plateID\n",
    "    lbepr_df['well'] = well\n",
    "    lbepr_df['field'] = field.replace(\"field_\",\"\")\n",
    "    tracking.close()\n",
    "    #Filter using the filter parameters\n",
    "    #remove short tracks that are not parents and are not in the last frame\n",
    "    #tracks_flt = lbepr_df.query('length >= @min_track_length or is_parent or ends > (@last_frame-@min_track_length)')\n",
    "    tracks_flt = lbepr_df.query('length >= @min_track_length or is_parent')\n",
    "    #write out the tracks.csv file \n",
    "    tracks_flt.to_csv(res_flt_filename,index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3e9ba5-0216-4676-aa67-b3c34b3bae65",
   "metadata": {},
   "source": [
    "#### Filter masks to only tracked cells  \n",
    "Use the filtered tracks to remove masks for non-cell objects  \n",
    "Save the filtered masks as individual image files in filtered_masks directory   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b64f79e-7108-49d5-ab3d-57c381ba8075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check on need to filter cell masks on tracking results for HC01701 B2 \n",
      "filtering cell masks on tracking results for HC01701 B2 field_1 \n",
      "filtering cell masks on tracking results for HC01701 B2 field_2 \n",
      "filtering cell masks on tracking results for HC01701 B2 field_3 \n",
      "filtering cell masks on tracking results for HC01701 B2 field_4 \n"
     ]
    }
   ],
   "source": [
    "#use the tracks.csv file to filter out cell masks\n",
    "sys.stdout.write(\"check on need to filter cell masks on tracking results for \"+plateID+\" \"+well+\" \\n\")\n",
    "\n",
    "for subdir in subdirectories:\n",
    "    field = re.findall(\"field_[1-9]\",subdir)[0]\n",
    "    mask_track_path = os.path.join(output_path,\"tracking\",well,field,\"results\")\n",
    "    tracked_mask_filenames = sorted(glob.glob(mask_track_path+\"/mask*\"))\n",
    "    cell_filtered_path = tracking_path+well+\"/\"+field+\"/cell_filtered_masks/\"\n",
    "    if debugging_flag:\n",
    "        tracked_mask_filenames = tracked_mask_filenames[0:10]\n",
    "        \n",
    "    if not os.path.exists(cell_filtered_path):\n",
    "        os.makedirs(cell_filtered_path, exist_ok=True)\n",
    "            \n",
    "    #condition on whether the filtered cell masks files exist\n",
    "    if len(os.listdir(cell_filtered_path)) == 0:\n",
    "        sys.stdout.write(\"filtering cell masks on tracking results for \"+plateID+\" \"+well+\" \"+field+\" \\n\")\n",
    "\n",
    "        #read in the tracks file for this field    \n",
    "        tracks_filename = os.path.join(output_path,\"tracking\",well,field,\"results\",\"tracks.csv\")\n",
    "        tracks = pd.read_csv(tracks_filename)\n",
    "        \n",
    "        #loop through the cell mask images in the field\n",
    "        for fn in tracked_mask_filenames:\n",
    "            #read in the cell mask image that tracking has relabeled to be consistent across images\n",
    "            im_cell = io.imread(fn)\n",
    "            \n",
    "            #replace any label that's not a cell based on the tracks file with a 0 value\n",
    "            cell_labels = np.array([x if x in tracks.label.to_numpy()\n",
    "                                       else 0 for x in range(0, im_cell.max()+1)])\n",
    "            im_cell_filtered = cell_labels[im_cell]\n",
    " \n",
    "            io.imsave(fn.replace(\"results\",\"cell_filtered_masks\"), im_cell_filtered.astype(np.int16), plugin='tifffile', check_contrast=False)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3343a4-ea3f-4edd-87df-ee3cf969e0ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7baa23-9e62-43f3-aa9d-4cd8c24503ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start nuclear segmentation of HC01701 B2 field_1\n"
     ]
    }
   ],
   "source": [
    "if cellline == \"AU565\":\n",
    "    n_diameter = 13\n",
    "elif cellline == \"HCC1143\":\n",
    "    n_diameter = 17\n",
    "elif cellline == \"21MT1\":\n",
    "    n_diameter = 28\n",
    "elif cellline == \"MDAMB157\":\n",
    "    n_diameter = 20\n",
    "elif cellline == \"HCC1143nlc\":\n",
    "    n_diameter = 13\n",
    "else:\n",
    "    n_diameter = 17\n",
    "\n",
    "n_model_loaded = False\n",
    "\n",
    "#Segment the nuclei using a second cellpose model\n",
    "#shrink the nuclei masks to better match the biomarkers in the images\n",
    "#filter the nuclei to those only within the cell masks\n",
    "#associate the nuclei with the cells based on maximum area within a cell\n",
    "##count the number of nuclei in each cell\n",
    "#relabel the nuclei to the same as the cell label\n",
    "#create a cyto mask by subtracting the nuclei from the cell\n",
    "for subdir in subdirectories:\n",
    "    field = re.findall(\"field_[1-9]\",subdir)[0]\n",
    "    field_num = re.findall(\"[0-9]\", field)[0]\n",
    "    track_path = os.path.join(output_path,\"tracking\",well,field)\n",
    "    nuc_filtered_masks_path = os.path.join(track_path,\"nuc_filtered_masks\")\n",
    "    cyto_filtered_masks_path = os.path.join(track_path,\"cyto_filtered_masks\")\n",
    "    csv_filename = track_path+\"/Nbr_nuclei.csv\"\n",
    "    if not os.path.exists(nuc_filtered_masks_path):\n",
    "        os.makedirs(nuc_filtered_masks_path, exist_ok=True)\n",
    "    if not os.path.exists(cyto_filtered_masks_path):\n",
    "        os.makedirs(cyto_filtered_masks_path, exist_ok=True)\n",
    "        \n",
    "    #condition on whether the nuclear and cyto masks exist\n",
    "    if np.logical_or(len(os.listdir(nuc_filtered_masks_path)) == 0,\n",
    "                     np.logical_or(len(os.listdir(cyto_filtered_masks_path)) == 0, not os.path.isfile(csv_filename))):\n",
    "        if not n_model_loaded:\n",
    "            n_flow_threshold = .4\n",
    "            n_cellprob_threshold=0\n",
    "            resample = True\n",
    "            # define CHANNELS to run segementation on\n",
    "            # grayscale=0, R=1, G=2, B=3\n",
    "            # channels = [cytoplasm, nucleus]\n",
    "            # if NUCLEUS channel does not exist, set the second channel to 0\n",
    "            n_channels = [0,0]\n",
    "\n",
    "            # DEFINE CELLPOSE MODEL\n",
    "            nuc_model = models.CellposeModel(gpu=True,  pretrained_model = \"/home/exacloud/gscratch/HeiserLab/images/cellpose_Ctc_\"+cellline+\"/train/models/Ctn\") #use a trained nuclear model\n",
    "            n_model_loaded = True\n",
    "\n",
    "        r_reg_filename = os.path.join(registered_stacks_path,plateID+\"_R_\"+well+\"_\"+field_num+\"_reg_stack.tif\")\n",
    "\n",
    "        sys.stdout.write(\"Start nuclear segmentation of \"+plateID + \" \"+ well + \" \" + field+\"\\n\")\n",
    "        img_rs_reg = io.imread(r_reg_filename)\n",
    "        #read in the cell masks that have been relabeled and filtered \n",
    "        cell_filtered_tracked_masks_filenames = sorted(glob.glob(track_path+\"/cell_filtered_masks/mask*\"))\n",
    "\n",
    "        if debugging_flag:\n",
    "            img_rs_reg = img_rs_reg[0:10]\n",
    "            \n",
    "        df_all = pd.DataFrame(columns = ['label','well','field', 'nuclei'])\n",
    "        for i, image in enumerate(img_rs_reg): #loop for each image\n",
    "            \n",
    "            #use the nuclear cellpose model to identify the nuclei within each cell\n",
    "            n_masks_raw, flows, styles = nuc_model.eval(image,\n",
    "                                                               diameter=n_diameter,\n",
    "                                                               net_avg = True,\n",
    "                                                               flow_threshold=n_flow_threshold,\n",
    "                                                               cellprob_threshold=n_cellprob_threshold,\n",
    "                                                               channels=n_channels)\n",
    "            \n",
    "            #shrink the masks to better match the biology\n",
    "            n_masks = morphology.erosion(n_masks_raw, morphology.disk(2))\n",
    "            \n",
    "            cell_masks = io.imread(cell_filtered_tracked_masks_filenames[i])\n",
    "\n",
    "            #use regionprops with the cell masks to get the nuclear labels\n",
    "            nuc_images = measure.regionprops_table(cell_masks, intensity_image=n_masks,\n",
    "                                               properties=('label', 'image', 'image_intensity', 'bbox'))   \n",
    "            #nuc_images is a list of bounding box images \n",
    "            #label is the cell label's value\n",
    "            #image is a 2d logical array of the cell mask in it's bounding box\n",
    "            #image_intensity is a 2d integer array of the nuclear mask labels in the cell's bounding box\n",
    "            \n",
    "            #Use the nuc_images list to create a new full image 2d nuclear mask where the nuclear mask values \n",
    "            #are the same as the cell masks they are within\n",
    "            \n",
    "            #create a dataframe with cell label, nuc label and nuc area columns where each row is a cell and the information comes from the cell bounding box\n",
    "            ####ToDo handle images with no nuclear objexcts to evaluate \n",
    "            cell_df_list = []\n",
    "            nbr_nuclei_list = []\n",
    "            cell_label_list = []\n",
    "            \n",
    "            for nuc_i, nuc_mask_labels in enumerate(nuc_images['image_intensity']): \n",
    "                #for each cell mask bounding box ...\n",
    "                #remove nuclear masks that are outside the cell mask\n",
    "                nuc_mask_labels[~nuc_images['image'][nuc_i]] = 0\n",
    "                \n",
    "                #get the nuclei mask values inside each cell mask\n",
    "                #need to handle these cases\n",
    "                #nuclei are in more than one cell - assign to the cell with the most area\n",
    "                #after nuclei are only in one cell...\n",
    "                #no nuclei in the cell - delete cell mask\n",
    "                #one nuclei in the cell - relabel the nuclei to the cell\n",
    "                #more than one nuclei in the cell - relabel all nuclei to the cell\n",
    "                \n",
    "                unique_nuc_labels = np.unique(nuc_mask_labels[nuc_mask_labels != 0])\n",
    "                #print(\"nuclear label(s) \"+str(unique_nuc_labels)+\" are in cell \"+str(nuc_images['label'][nuc_i]))\n",
    "                #Keep track of the unique number of nuceli in each cell\n",
    "                \n",
    "                #for each mask, get the number of pixels inside the cell\n",
    "                if(unique_nuc_labels.size != 0):\n",
    "                    nuc_masks, counts = np.unique([element for element in nuc_mask_labels.ravel() if element != 0], return_counts=True)\n",
    "                    cell_df = pd.DataFrame({'Cell': nuc_images['label'][nuc_i], 'Nuc_mask': nuc_masks, 'area':counts})\n",
    "                    cell_df_list.append(cell_df)\n",
    "\n",
    "            #build a new nuclei mask image with nuclei clipped to within one cell and using the cell's label \n",
    "            final_nuc_mask_image = np.zeros(n_masks.shape, like = n_masks).astype(int)\n",
    "            \n",
    "            if(len(cell_df_list) >0): #update final nuc mask if there nuclei detected in the image\n",
    "                cell_df = pd.concat(cell_df_list, ignore_index = True)\n",
    "            \n",
    "                #use the cell dataframe to assign nuclei to cells based on max area in the cell\n",
    "                cell_df = cell_df.sort_values(['area'],ascending=False).groupby('Nuc_mask').head(1).sort_index(ignore_index=True)\n",
    "\n",
    "                nbr_nuclei_list = []\n",
    "                cell_label_list = []\n",
    "                for cell_i, nuc_mask_image in enumerate(nuc_images['image_intensity']): #loop through each cell mask\n",
    "                    #don't process the nuclei if it's not within a cell\n",
    "                    if(nuc_images['label'][cell_i] in cell_df['Cell'].to_numpy()):\n",
    "                        #clip the nuclei to within the cell mask\n",
    "                        nuc_mask_image[~nuc_images['image'][cell_i]] = 0\n",
    "                        #nuc_masks_within_cell = np.ma.masked_array(nuc_mask_image, nuc_images['image'][cell_i]).data \n",
    "                        #zero out nuclei not associated with this cell\n",
    "                        #find the nuclei associated with this cell\n",
    "                        associated_nuclei = cell_df['Nuc_mask'][cell_df['Cell'] == nuc_images['label'][cell_i]].to_numpy()\n",
    "                        nuc_associated_mask = np.isin(nuc_mask_image, associated_nuclei)\n",
    "                        nuc_mask_image[~nuc_associated_mask] = 0\n",
    "\n",
    "                        #Keep track of the unique number of nuclei in each cell\n",
    "                        nbr_nuclei_list.append(len(associated_nuclei))\n",
    "                        cell_label_list.append(nuc_images['label'][cell_i])\n",
    "\n",
    "                        #Relabel nuclei associated with this cell to the cell's label\n",
    "                        nuc_mask_image[nuc_associated_mask] = nuc_images['label'][cell_i]\n",
    "\n",
    "                        #Use the bounding box origin to add the nuclei to the final mask\n",
    "                        min_row = nuc_images['bbox-0'][cell_i]\n",
    "                        min_col = nuc_images['bbox-1'][cell_i]\n",
    "                        max_row = nuc_images['bbox-2'][cell_i]\n",
    "                        max_col = nuc_images['bbox-3'][cell_i]\n",
    "                        #place the labels into the correct place in the final image\n",
    "                        #do not 0 out the existing values where there are 0's\n",
    "                        final_nuc_mask_image[min_row:max_row,min_col:max_col] = final_nuc_mask_image[min_row:max_row,min_col:max_col] + nuc_mask_image\n",
    "\n",
    "            io.imsave(cell_filtered_tracked_masks_filenames[i].replace(\"cell_\",\"nuc_\"), final_nuc_mask_image, plugin='tifffile', check_contrast=False)\n",
    "            io.imsave(cell_filtered_tracked_masks_filenames[i].replace(\"cell_\",\"cyto_\"), cell_masks-final_nuc_mask_image, plugin='tifffile', check_contrast=False)\n",
    "            if(np.logical_and(len(cell_label_list) >0,len(nbr_nuclei_list) >0)): \n",
    "                #save the number of nuclei in each cell to disk\n",
    "                df = pd.DataFrame(list(zip(cell_label_list, nbr_nuclei_list)),columns =['label', 'nuclei'])\n",
    "                df['slice'] = str(i)\n",
    "                df_all = pd.concat([df_all, df], ignore_index = True)\n",
    "        df_all['well'] = well\n",
    "        df_all['field'] = field_num\n",
    "        df_all.to_csv(csv_filename, index = False)\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920663ea-8b5f-458e-b163-aff3fe70f685",
   "metadata": {},
   "source": [
    "#### Get excel metadata file  \n",
    "If this file does not exists, create a level 0 file that is data only  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd04662-f03b-41c9-ade5-e08d5c430f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If the metadata exists, load it\n",
    "metadata_filename = os.path.join(data_path,plateID,\"metadata\",plateID+\".xlsx\")\n",
    "\n",
    "if os.path.exists(metadata_filename):\n",
    "    md_all = pd.read_excel(metadata_filename, engine='openpyxl', dtype={'Drug1Concentration': str, 'Drug2Concentration': str})\n",
    "    \n",
    "    #remove unwanted columns read in from the excel files\n",
    "    r = re.compile(\"Unnamed.*\")\n",
    "    columns_to_drop = list(filter(r.match, md_all.columns)) \n",
    "    metadata = md_all.drop(columns = columns_to_drop)\n",
    "    \n",
    "    #match metadata and data well labels format\n",
    "    metadata['row'] = [re.sub(r'[0-9]*', '', Well) for Well in metadata['Well']]\n",
    "    metadata['column'] = [re.sub(r'[A-Z]', '', Well) for Well in metadata['Well']]\n",
    "    metadata['column'] = [re.sub(r'\\A0', '', row) for row in metadata['column']]\n",
    "    metadata['well'] = metadata['row'] + metadata['column']\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81e334b-5d61-49e0-aa54-8dcf31527fa8",
   "metadata": {},
   "source": [
    "#### Pull data from images  \n",
    "Apply the filtered masks to the registered red nuclear channel and recored each cells nuclear morphology, intensity and texture  \n",
    "Create cytoplasm masks by expanding the nuclear masks by a fixed amount or until they collide with another nuclear expansion  \n",
    "Use the nuclear and cytoplasmic masks to measure intensities in the green fluroescent images  \n",
    "Calculate intensity ratios between the cytomplasm and nuclei  \n",
    "If the metadata is available, merge it with the cell level data  \n",
    "Store the cell level data (and metadata) in a csv file where each row is a cell  \n",
    "Data feature values can be decoded as follows:  \n",
    "\\<compartment>\\_\\<pipeline name>\\_\\<channel name>\\_\\<regionprops name>  \n",
    "compartment - Nuclei, Cyto or Cell  \n",
    "pipeline name - PC for python cellpose or other if added  \n",
    "channel name - NR for nuclear reporter, CC for cell cycle reporter or others if added  \n",
    "regionprops name - label passed through from the skimage measure.regionprops function https://scikit-image.org/docs/dev/api/skimage.measure.html#skimage.measure.regionprops  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d5a4ea-6df5-4114-8291-6755e26433e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#minutes_between_images = 30\n",
    "neighborhood_nuclei_distance = 5\n",
    "neighborhood_radius_near = 20\n",
    "neighborhood_radius_medium = 45\n",
    "neighborhood_radius_far = 70\n",
    "ratio_box_side_length = 10\n",
    "\n",
    "#use the first two raw image file names to determine the time between images\n",
    "two_filenames = sorted(glob.glob(os.path.join(subdirectories[0],\"*_R_*m.tif\")))[0:2]\n",
    "minutes_between_images = int(re.sub('(.*_..d..h)|(m.tif)','',two_filenames[1]))-int(re.sub('(.*_..d..h)|(m.tif)','',two_filenames[0]))\n",
    "\n",
    "#loop through the fields in the well\n",
    "for subdir in subdirectories:\n",
    "    field = re.findall(\"field_[1-9]\",subdir)[0]\n",
    "    field_num = re.findall(\"[0-9]\", field)[0]\n",
    "    l0_filename = os.path.join(data_path+plateID,\"Analysis\",pipeline_name,plateID+\"_\"+well+\"_\"+field+\"_level_0.csv\")\n",
    "    ratio_stack_filename = os.path.join(output_path,plateID+\"_\"+well+\"_\"+field_num+\"_ratios.tif\")\n",
    "\n",
    "    #condition on whether the l1 and l2 files exist\n",
    "    if not os.path.exists(l0_filename.replace('level_0','level_1')):\n",
    "        sys.stdout.write(\"Pulling data from images \"+l0_filename.replace('_level_0.csv','')+\"\\n\")\n",
    "        cyto_filtered_mask_path = os.path.join(output_path,\"tracking\",well,field,\"cyto_filtered_masks\")\n",
    "        nuc_filtered_mask_path = os.path.join(output_path,\"tracking\",well,field,\"nuc_filtered_masks\")\n",
    "        cyto_tracked_mask_filenames = sorted(glob.glob(cyto_filtered_mask_path+\"/mask*\"))\n",
    "        img_gs_reg = io.imread(os.path.join(registered_stacks_path,plateID+\"_G_\"+well+\"_\"+field.replace(\"field_\",\"\")+\"_reg_stack.tif\"))\n",
    "        img_rs_reg = io.imread(os.path.join(registered_stacks_path,plateID+\"_R_\"+well+\"_\"+field.replace(\"field_\",\"\")+\"_reg_stack.tif\"))\n",
    "\n",
    "        # iterate over the mask files\n",
    "        results = []\n",
    "        ratio_image_list = []\n",
    "        for i, fn in enumerate(cyto_tracked_mask_filenames):\n",
    "            #read in the cyto mask image\n",
    "            cyto_masks = io.imread(fn)\n",
    "            #read in the nuclear mask image\n",
    "            nuc_masks = io.imread(fn.replace(\"cyto_\",\"nuc_\"))\n",
    "            #read in registered cell cycle images\n",
    "            #reg_fn = fn.replace(\"filtered_masks\",\"reg\") #registered phase\n",
    "            image = img_gs_reg[i]\n",
    "            image_nr = img_rs_reg[i]\n",
    "\n",
    "            #measure cell cycle reporter intensity and nuclear morphology, texture\n",
    "            cyto = measure.regionprops_table(cyto_masks, intensity_image=image,\n",
    "                                               properties=('label',\n",
    "                                                           'area','bbox_area','convex_area','centroid','eccentricity','equivalent_diameter','extent','feret_diameter_max','filled_area',\n",
    "                                                            'major_axis_length','minor_axis_length','moments_hu','perimeter','perimeter_crofton','solidity',\n",
    "                                                            'mean_intensity','max_intensity','min_intensity'))\n",
    "            nuc = measure.regionprops_table(nuc_masks, intensity_image=image,\n",
    "                                   properties=('label',\n",
    "                                               'area','bbox_area','convex_area','centroid','eccentricity','equivalent_diameter','extent','feret_diameter_max','filled_area',\n",
    "                                                'major_axis_length','minor_axis_length','moments_hu','perimeter','perimeter_crofton','solidity',\n",
    "                                                'mean_intensity','max_intensity','min_intensity'))\n",
    "            \n",
    "            #measure features of the nuclear reporter\n",
    "            cyto_nr = measure.regionprops_table(cyto_masks, intensity_image=image_nr,\n",
    "                                               properties=('label',\n",
    "                                                            'mean_intensity','max_intensity','min_intensity'))\n",
    "            nuc_nr = measure.regionprops_table(nuc_masks, intensity_image=image_nr,\n",
    "                                   properties=('label','mean_intensity','max_intensity','min_intensity'))\n",
    "            \n",
    "            # turn results into a dataframe\n",
    "            cyto_data = pd.DataFrame(cyto)\n",
    "            cyto_data.rename(columns={col: 'Cyto_'+ch2_name+'_'+col  for col in cyto_data.columns if col not in ['label']}, inplace=True)\n",
    "\n",
    "            nuc_data = pd.DataFrame(nuc)\n",
    "            nuc_data.rename(columns={col: 'Nuclei_'+ch2_name+'_'+col  for col in nuc_data.columns if col not in ['label']}, inplace=True)\n",
    "            \n",
    "            cyto_nr_data = pd.DataFrame(cyto_nr)\n",
    "            cyto_nr_data.rename(columns={col: 'Cyto_'+ch1_name+'_'+col  for col in cyto_nr_data.columns if col not in ['label']}, inplace=True)\n",
    "\n",
    "            nuc_nr_data = pd.DataFrame(nuc_nr)\n",
    "            nuc_nr_data.rename(columns={col: 'Nuclei_'+ch1_name+'_'+col  for col in nuc_nr_data.columns if col not in ['label']}, inplace=True)\n",
    "            \n",
    "            # recover the well and field values and add them to the dataframe\n",
    "            well = re.findall('/[A-Z][0-9]+/',fn)[0]\n",
    "            well = re.sub('/','', well)\n",
    "            cyto_data['well'] = well\n",
    "            field = re.findall('field_[0-9]+',fn)[0]\n",
    "            field_num = int(re.sub('field_','', field))\n",
    "            cyto_data['field'] = field_num\n",
    "            cyto_data['slice'] = i\n",
    "            cyto_data['elapsed_minutes'] = i*minutes_between_images #assumes time slice numbering starts at 1\n",
    "            elapsed_minutes = i*minutes_between_images #assumes time slice numbering starts at 1\n",
    "            day = np.floor(elapsed_minutes/(24*60)).astype(int)\n",
    "            hour = np.floor((elapsed_minutes-day*(24*60))/60).astype(int)\n",
    "            minute = np.floor(elapsed_minutes-day*(24*60)-hour*60).astype(int)\n",
    "            day = str(day).zfill(2)\n",
    "            hour = str(hour).zfill(2)\n",
    "            minute = str(minute).zfill(2)\n",
    "            cyto_data['time_slice'] = day+\"d\"+hour+\"h\"+minute+\"m\"\n",
    "\n",
    "            #calculate the neighborhood density on the nuclei centroids ###TODO replace with a measure of cytoplasm\n",
    "            nuc_kd = spatial.KDTree(nuc_data[['Nuclei_CC_centroid-0','Nuclei_CC_centroid-1']])\n",
    "            nuc_data['neighborhood_'+str(neighborhood_radius_near)] = nuc_kd.query_ball_point(nuc_data[['Nuclei_CC_centroid-0','Nuclei_CC_centroid-1']],\n",
    "                                                                                                    r = neighborhood_radius_near, return_sorted = True, return_length=True)\n",
    "            nuc_data['neighborhood_'+str(neighborhood_radius_medium)] = nuc_kd.query_ball_point(nuc_data[['Nuclei_CC_centroid-0','Nuclei_CC_centroid-1']],\n",
    "                                                                                                    r = neighborhood_radius_medium, return_sorted = True, return_length=True)\n",
    "            nuc_data['neighborhood_'+str(neighborhood_radius_far)] = nuc_kd.query_ball_point(nuc_data[['Nuclei_CC_centroid-0','Nuclei_CC_centroid-1']],\n",
    "                                                                                                    r = neighborhood_radius_far, return_sorted = True, return_length=True)\n",
    "                        \n",
    "            #merge the dataframes from the different channels, retain all cells even if there is no nuclear mask\n",
    "            df_ch1 = pd.merge(cyto_nr_data, nuc_nr_data, how=\"left\", on=[\"label\"])\n",
    "            df_ch2 = pd.merge(cyto_data, nuc_data, how=\"left\", on=[\"label\"])\n",
    "            df_all = pd.merge(df_ch1, df_ch2, how=\"left\", on=[\"label\"])\n",
    "\n",
    "            #Calculate ratio of ch2 cyto to nuclei intensities\n",
    "            df_all['Cell_'+ch2_name+'_mean_intensity_ratio'] = df_all['Cyto_'+ch2_name+'_mean_intensity']/df_all['Nuclei_'+ch2_name+'_mean_intensity']\n",
    "            df_all['Cell_'+ch2_name+'_max_intensity_ratio'] = df_all['Cyto_'+ch2_name+'_max_intensity']/df_all['Nuclei_'+ch2_name+'_max_intensity']\n",
    "            df_all['Cell_'+ch2_name+'_min_intensity_ratio'] = df_all['Cyto_'+ch2_name+'_min_intensity']/df_all['Nuclei_'+ch2_name+'_min_intensity']\n",
    "\n",
    "            #create an image with a small rectangle of the mean intensity ratio centered on each nuclei\n",
    "            ratio_image = np.zeros_like(image)\n",
    "            for i , ratio in enumerate(df_all['Cell_'+ch2_name+'_mean_intensity_ratio']):\n",
    "                if not np.isnan(ratio):\n",
    "                    center_y = df_all['Nuclei_CC_centroid-0'][i]\n",
    "                    center_x = df_all['Nuclei_CC_centroid-1'][i]\n",
    "                    x_start = (center_x - ratio_box_side_length/2).astype(int)\n",
    "                    x_start = np.clip(x_start, 0, image.shape[1])\n",
    "                    x_end = (center_x + ratio_box_side_length/2).astype(int)\n",
    "                    x_end = np.clip(x_end, 0, image.shape[1])\n",
    "                    y_start = (center_y - ratio_box_side_length/2).astype(int)\n",
    "                    y_start = np.clip(y_start, 0, image.shape[0])\n",
    "                    y_end = (center_y + ratio_box_side_length/2).astype(int)\n",
    "                    y_end = np.clip(y_end, 0, image.shape[0])\n",
    "                    #clip positions to within image\n",
    "                    ratio_image[y_start:y_end, x_start:x_end] = int((ratio*100))\n",
    "\n",
    "            # append this ratio_images to the list\n",
    "            ratio_image_list.append(ratio_image)\n",
    "            # append this image's dataframe to the results list\n",
    "            results.append(df_all)\n",
    "            \n",
    "        #save the ratio stack to disk\n",
    "        io.imsave(ratio_stack_filename, np.array(ratio_image_list, dtype = 'uint16'), plugin='tifffile', check_contrast=False)\n",
    "\n",
    "        #concatenate all of the results from all images in the field\n",
    "        l0_image = pd.concat(results)\n",
    "\n",
    "        #join with the tracking results to get lineage, parent, frame length values\n",
    "        tracks_filename = os.path.join(output_path,\"tracking\",well,\"field_\"+str(field_num),\"results/tracks.csv\")\n",
    "        tracks = pd.read_csv(tracks_filename)\n",
    "        l0_tracks = pd.merge(l0_image, tracks, how=\"left\", on=[\"label\", \"well\", \"field\"])\n",
    "        \n",
    "        #join with the nuclei counts   ######TODO\n",
    "        nuc_count_filename = os.path.join(output_path,\"tracking\",well,\"field_\"+str(field_num),\"Nbr_nuclei.csv\")\n",
    "        nuc_counts = pd.read_csv(nuc_count_filename)\n",
    "        l0 = pd.merge(l0_tracks, nuc_counts, how=\"left\", on=[\"label\", \"well\", \"field\", \"slice\"])\n",
    "\n",
    "        if os.path.exists(metadata_filename):\n",
    "            #merge data and metadata on well values\n",
    "            l1= pd.merge(l0, metadata, how=\"left\", on=[\"well\"]).round(decimals=2)\n",
    "            l1['treatment'] =  l1['Drug1']+'_'+l1['Drug1Concentration']+'_'+l1['Drug2']+'_'+l1['Drug2Concentration']\n",
    "            sys.stdout.write(\"Writing \"+l0_filename.replace('level_0','level_1') + \" to disk\"+\"\\n\")\n",
    "            l1.to_csv(l0_filename.replace('level_0','level_1'), index = False)\n",
    "        else:\n",
    "            sys.stdout.write(\"no metadata file for \"+plateID+\" so creating level 0 file\"+\"\\n\")\n",
    "            l0 = l0.round(decimals=2)\n",
    "            l0.to_csv(l0_filename, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbc9ca5-2375-470e-ab37-526631efb473",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e563ed-5fea-4204-bf59-8f4e0dad535e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
