{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6783c1f-24b5-4da5-b434-9e9559777f43",
   "metadata": {},
   "source": [
    "### Apply ilastik masks and save cell-level data with metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6a8e734-b8d6-4d70-a4f8-c8e5d1a31550",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, re, glob, sys\n",
    "from skimage import io, morphology, segmentation, measure\n",
    "import h5py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a12159e-9e73-4b49-afb4-e9e918f2e36c",
   "metadata": {},
   "source": [
    "Instead of using Cellprofiler, convert the pixel masks to nuclei masks and apply them to the green images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80b5b982-8608-449e-a466-b90d7be03014",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_name = 'PI' # python + ilastik\n",
    "data_path = '/home/exacloud/gscratch/HeiserLab/images/'\n",
    "plateID = 'AU00602' #sys.argv[1]\n",
    "well = 'D3' #sys.argv[2]\n",
    "input_files_path = os.path.join(data_path+plateID,\"Analysis\",pipeline_name,\"intermediate_files\")\n",
    "image_stack_paths = sorted(glob.glob(input_files_path+\"/\"+plateID+\"_RGP_\"+well+\"*stack.tif\"))\n",
    "mask_paths = sorted(glob.glob(input_files_path+\"/\"+plateID+\"_RGP_\"+well+\"*Segmentation.h5\"))\n",
    "mainpath = os.path.join(data_path,plateID,\"Analysis\",pipeline_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd4c3c58-0e98-4b0c-872b-547a7bf77e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "ch1_name = 'NR'\n",
    "ch2_name = 'CC'\n",
    "cyto_expansion = 5\n",
    "minimum_nuclear_radius = 3\n",
    "minimum_nuclear_area = 3.14*minimum_nuclear_radius**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1175e87-6a22-4562-a07d-778fa60fb31c",
   "metadata": {},
   "source": [
    "Get the green raw image files and apply the mask to extract the intensity data. Extract morphology values from the masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fb98a96-f47b-447f-9b7c-f39a45f1df83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing files in /home/exacloud/gscratch/HeiserLab/images/AU00602/Analysis/PI/intermediate_files/AU00602_RGP_D3_1_stack_Simple Segmentation.h5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-937173932abe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m#Done processing all of the images in the sequence so concatenate all of the dataframes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mresults_pd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;31m#concatenate all of the results from the sequences in the well\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/exacloud/gscratch/HeiserLab/software/miniconda3/envs/biapy/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     )\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/exacloud/gscratch/HeiserLab/software/miniconda3/envs/biapy/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No objects to concatenate\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for mask_path in mask_paths: #Each mask_path is a sequence of images\n",
    "    print(\"processing files in \"+mask_path)\n",
    "    #load the pixel masks\n",
    "    f = h5py.File(mask_path, 'r')\n",
    "    mask_dataset = f['exported_data']\n",
    "    masks_stack = np.stack(mask_dataset)\n",
    "    nuclei_masks_raw = masks_stack == 4 # set nuclei pixels to True and the rest to False\n",
    "\n",
    "    #load the corresponding green images\n",
    "    field = re.findall(\"_[1-9]_\",mask_path)[0]\n",
    "    field_num = re.findall(\"[1-9]\", field)[0]\n",
    "\n",
    "    g_data_paths = glob.glob(os.path.join(data_path,plateID,well,\"field_\"+field_num,\"*_G_*.tif\"))\n",
    "    img_g_ic = io.imread_collection(g_data_paths) # 3 dimensions : frames x width x height sorted by name\n",
    "    img_gs = np.stack(img_g_ic)\n",
    "    \n",
    "    #read in the corresponding data file names to get time slices\n",
    "    with open(re.sub(\"stack_Simple Segmentation.h5\",\"filenames.txt\", mask_path)) as f:\n",
    "        filenames = f.readlines()\n",
    "    \n",
    "    for img_num, image in enumerate(nuclei_masks_raw[:,:,:,0]): #process each image in the mask_path sequence of images\n",
    "\n",
    "        # open masks to delete small regions\n",
    "        nuclei_masks_open = morphology.binary_opening(image, selem=morphology.disk(2))     \n",
    "\n",
    "        # label the masks with unique integers starting at 0\n",
    "        nuclei_masks_all = measure.label(nuclei_masks_open)\n",
    "        #read in filenames to get time slice data\n",
    "        #need to ensure there are nuclei pixels to process\n",
    "        if np.amax(nuclei_masks_all) >0: #Only process if there is at least one mask\n",
    "            nuclei_g = measure.regionprops_table(nuclei_masks_all, intensity_image = img_gs[img_num], properties=('label', 'area'))\n",
    "\n",
    "            #remove masks too small to be a nucleus\n",
    "            indices_to_keep = np.array([x if x-1 in np.argwhere(nuclei_g['area']>minimum_nuclear_area)\n",
    "                                    else 0 for x in range(nuclei_g['label'].max()+1)])\n",
    "            nuclei_masks = indices_to_keep[nuclei_masks_all]\n",
    "            nuclei_g = measure.regionprops_table(nuclei_masks, intensity_image = img_gs[img_num], properties=('label', 'area','eccentricity',\n",
    "                                                                                                                          'mean_intensity','max_intensity','min_intensity'))\n",
    "            #expand the masks to get cytoplasmic regions\n",
    "            nuclei_boundaries = segmentation.find_boundaries(nuclei_masks, mode='thick')*nuclei_masks\n",
    "            nuclei_expansions = segmentation.expand_labels(nuclei_masks, cyto_expansion) - nuclei_masks + nuclei_boundaries\n",
    "            nuclei_exp_g = measure.regionprops_table(nuclei_expansions, intensity_image = img_gs[img_num],\n",
    "                                                     properties=('label','mean_intensity','max_intensity','min_intensity'))\n",
    "\n",
    "            # turn results into a dataframe\n",
    "            nuclei_g_data = pd.DataFrame(nuclei_g)\n",
    "            nuclei_g_data.rename(columns={col: 'Nuclei_'+pipeline_name+'_' +ch2_name+'_'+col  for col in nuclei_g_data.columns if col not in ['label']}, inplace=True)\n",
    "\n",
    "            nuclei_exp_g_data = pd.DataFrame(nuclei_exp_g)\n",
    "            nuclei_exp_g_data.rename(columns={col: 'Cyto_'+pipeline_name+'_' +ch2_name+'_'+col  for col in nuclei_exp_g_data.columns if col not in ['label']}, inplace=True)\n",
    "\n",
    "            # add an image number and collect the data                                                                                                             \n",
    "            nuclei_g_data['image'] = img_num+1\n",
    "\n",
    "            #Calculate ratio of ch2 cyto to nuclei intensities\n",
    "            nuclei_exp_g_data['Cell_'+pipeline_name+'_' +ch2_name+'_mean_intensity_ratio'] = nuclei_exp_g_data['Cyto_'+pipeline_name+'_' +ch2_name+'_mean_intensity']/nuclei_g_data['Nuclei_'+pipeline_name+'_' +ch2_name+'_mean_intensity']\n",
    "            nuclei_exp_g_data['Cell_'+pipeline_name+'_' +ch2_name+'_max_intensity_ratio'] = nuclei_exp_g_data['Cyto_'+pipeline_name+'_' +ch2_name+'_max_intensity']/nuclei_g_data['Nuclei_'+pipeline_name+'_' +ch2_name+'_max_intensity']\n",
    "            nuclei_exp_g_data['Cell_'+pipeline_name+'_' +ch2_name+'_min_intensity_ratio'] = nuclei_exp_g_data['Cyto_'+pipeline_name+'_' +ch2_name+'_min_intensity']/nuclei_g_data['Nuclei_'+pipeline_name+'_' +ch2_name+'_min_intensity']\n",
    "\n",
    "            # add the well and field values to the dataframe\n",
    "            nuclei_g_data['well'] = well\n",
    "            nuclei_g_data['field'] = field_num\n",
    "            #add the time slice to the dataframe\n",
    "            nuclei_g_data['time_slice'] = re.findall(\"[0-9d]{3}[0-9h]{3}[0-9m]{3}\", filenames[img_num])[0]\n",
    "\n",
    "            #concatenate the dataframes\n",
    "            df_all = pd.concat([nuclei_g_data, nuclei_exp_g_data], axis=1, join=\"outer\")\n",
    "            #append this image's data to the rest of the data\n",
    "            results.append(df_all)\n",
    "    #Done processing all of the images in the sequence so concatenate all of the dataframes\n",
    "    results_pd = pd.concat(results)\n",
    "\n",
    "#concatenate all of the results from the sequences in the well\n",
    "l0 = pd.concat(results)\n",
    "\n",
    "    #Save mask image\n",
    "    #mask_filename = data_path+plateID+'/'+well+'/'+field+'/output_stacks/'+well+'_'+field+'_image'+str(img_num)+'_nuclei_masks.tif'\n",
    "        #io.imsave(mask_filename, nuclei_masks.astype('uint16'))\n",
    "        #cyto_mask_filename = data_path+plateID+'/'+well+'/'+field+'/output_stacks/'+well+'_'+field+'_image'+str(img_num)+'_cyto_masks.tif'\n",
    "        #io.imsave(cyto_mask_filename, nuclei_expansions.astype('uint16'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11effcfc-105b-47a4-acb5-df6d097f7d24",
   "metadata": {},
   "source": [
    "If the metadata files exists, combine the data with the experimental metadata and write out a level 1 file. Otherwise, write out a level 0 file so we don't waste the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a12ff90-7d41-418d-afdb-0e18f6f477e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding AU00601 metadata\n"
     ]
    }
   ],
   "source": [
    "#If the metadata exists, join it to the data and write out as a level 1 file\n",
    "metadata_filename = os.path.join(data_path,plateID,\"metadata\",plateID+\".xlsx\")\n",
    "if not os.path.exists(mainpath):\n",
    "    os.makedirs(mainpath, exist_ok=True)\n",
    "if os.path.exists(metadata_filename):\n",
    "    print(\"adding \"+plateID+\" metadata\")\n",
    "    md_all = pd.read_excel(metadata_filename, engine='openpyxl')\n",
    "    \n",
    "    #remove unwanted columns read in from the excel files\n",
    "    r = re.compile(\"Unnamed.*\")\n",
    "    columns_to_drop = list(filter(r.match, md_all.columns)) \n",
    "    metadata = md_all.drop(columns = columns_to_drop)\n",
    "    \n",
    "    #match metadata and data well labels format\n",
    "    metadata['column'] = [re.sub(r'[0-9]*', '', Well) for Well in metadata['Well']]\n",
    "    metadata['row'] = [re.sub(r'[A-Z]', '', Well) for Well in metadata['Well']]\n",
    "    metadata['row'] = [re.sub(r'\\A0', '', row) for row in metadata['row']]\n",
    "    metadata['well'] = metadata['column'] + metadata['row']\n",
    "    \n",
    "    #merge data and metadata on well values\n",
    "    l1= pd.merge(l0, metadata, how=\"left\", on=[\"well\"])\n",
    "    l1.to_csv(os.path.join(mainpath,plateID+'_'+well+'_level_1.csv'))\n",
    "else:\n",
    "    print(\"no metadata file for \"+plateID+\" so creating level 0 file\")\n",
    "    l0.to_csv(os.path.join(mainpath,plateID+'_'+well+'_level_0.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ced6663-736d-48a2-a64b-d6148980720c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biapy",
   "language": "python",
   "name": "biapy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
